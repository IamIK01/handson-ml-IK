{"cells":[{"cell_type":"markdown","metadata":{"id":"q1hEBbr2cbfH"},"source":["### 1. Is it OK to initialize all the weights to the same value as long as that value is selected randomly using He initialization?\n","\n","No, it is not OK to initialize all the weights to the same value, even if that value is selected randomly using He initialization. Initializing all weights to the same value would make the neurons symmetric, leading them to learn the same features and gradients, which in turn would prevent the network from learning effectively. It is essential to initialize weights with different values to break the symmetry and allow each neuron to learn different features.\n","\n","### 2. Is it OK to initialize the bias terms to 0?\n","\n","Yes, it is generally OK to initialize the bias terms to 0. Unlike weights, biases do not need to break symmetry because they are added after the weights are applied, and their primary role is to shift the activation function. Therefore, initializing biases to 0 is a common practice.\n","\n","### 3. Name three advantages of the SELU activation function over ReLU.\n","\n","1. **Self-Normalizing:** SELU activation functions tend to push the activations towards zero mean and unit variance, which helps maintain a self-normalizing property throughout the network. This can lead to faster convergence and more stable training.\n","\n","2. **Internal Covariate Shift Reduction:** By maintaining zero mean and unit variance, SELU helps in reducing the internal covariate shift, which can further improve the training efficiency and convergence speed.\n","\n","3. **No Dead Neurons:** Unlike ReLU, which can suffer from the dying ReLU problem where neurons can become inactive and never recover, SELU ensures that neurons continue to learn and adapt throughout the training process.\n","\n","### 4. In which cases would you want to use each of the following activation functions?\n","\n","- **SELU:**\n","  - When building deep neural networks with many layers, as it helps in maintaining the self-normalizing property, leading to more stable and faster training.\n","  - Particularly useful in fully connected deep neural networks.\n","\n","- **Leaky ReLU (and its variants):**\n","  - When dealing with the dying ReLU problem, where some neurons become inactive. Leaky ReLU allows a small gradient when the unit is not active.\n","  - Variants like Parametric ReLU (PReLU) can be useful when the model can learn the optimal slope of the negative part.\n","\n","- **ReLU:**\n","  - When training deep neural networks where speed and simplicity are essential.\n","  - Commonly used in convolutional neural networks (CNNs) due to its efficiency and effectiveness in practice.\n","\n","- **Tanh:**\n","  - When the data is centered around zero, as tanh outputs values between -1 and 1, making it useful for dealing with negative input values.\n","  - Can be preferred over logistic sigmoid in some cases due to its zero-centered output.\n","\n","- **Logistic (Sigmoid):**\n","  - When dealing with binary classification problems, especially in the output layer where probabilities are required.\n","  - Useful for models that require a probabilistic interpretation of the output.\n","\n","- **Softmax:**\n","  - In the output layer of neural networks for multi-class classification problems.\n","  - Converts the logits into probabilities, ensuring that the sum of the probabilities equals 1.\n","\n","### 5. What may happen if you set the momentum hyperparameter too close to 1 (e.g., 0.99999) when using an SGD optimizer?\n","\n","If the momentum hyperparameter is set too close to 1 (e.g., 0.99999), the updates may become too aggressive and oscillate around the minima, making it difficult for the optimizer to converge. This can lead to unstable training and may cause the optimizer to overshoot the optimal point repeatedly. It is important to find a balance where momentum helps accelerate convergence without causing excessive oscillations.\n","\n","### 6. Name three ways you can produce a sparse model.\n","\n","1. **L1 Regularization (Lasso):** Adding an L1 regularization term to the loss function encourages the model to produce weights that are exactly zero, leading to a sparse model.\n","\n","2. **Pruning:** Removing weights or neurons with the smallest magnitudes after training can produce a sparse model. This can be done gradually during or after the training process.\n","\n","3. **Sparse Initialization:** Starting with a sparse initialization of the weights, where most weights are set to zero, and only a few are non-zero. This can be particularly useful in certain types of models like sparse autoencoders.\n","\n","### 7. Does dropout slow down training? Does it slow down inference (i.e., making predictions on new instances)? What about MC Dropout?\n","\n","- **Dropout and Training:**\n","  - Dropout does slow down training because each training iteration involves randomly dropping units, which adds computational overhead. Additionally, the effective learning rate is reduced as the model needs to learn with fewer active neurons in each iteration.\n","\n","- **Dropout and Inference:**\n","  - Dropout does not slow down inference because it is typically turned off during the prediction phase. During inference, the full network is used, and the weights are scaled to account for the dropped units during training.\n","\n","- **MC Dropout:**\n","  - Monte Carlo (MC) Dropout does slow down inference because it involves performing multiple forward passes with dropout enabled to estimate uncertainty. This requires significantly more computation compared to a single forward pass without dropout.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UXQx4lHicbfL"},"source":["### 8. Practice training a deep neural network on the CIFAR10 image dataset:\n","\n","#### a. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation function"]},{"cell_type":"code","source":["!pip install tensorflow-addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rCK8Am-G5cMa","executionInfo":{"status":"ok","timestamp":1715769723259,"user_tz":-60,"elapsed":10856,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"7731456e-2514-48d4-854f-61d7b5ed13d7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOzw4z_KcbfM","executionInfo":{"status":"ok","timestamp":1715769723259,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"264e4f9f-0c58-462f-dc67-720f6b45dd53"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["# 1. Import Libraries:\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, ELU, AlphaDropout\n","from tensorflow.keras.initializers import HeNormal\n","from tensorflow.keras.optimizers import Nadam\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n"]},{"cell_type":"code","source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RO7J_8BRf3lZ","executionInfo":{"status":"ok","timestamp":1715769726182,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"9ef92044-5381-4383-cc56-5bc287f28c9e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n"]}]},{"cell_type":"code","source":["# Enable GPU memory growth\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)"],"metadata":{"id":"1TxgTeWfgJBX","executionInfo":{"status":"ok","timestamp":1715769727730,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":31,"metadata":{"id":"L60x0H7tcbfO","executionInfo":{"status":"ok","timestamp":1715771075677,"user_tz":-60,"elapsed":15,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"outputs":[],"source":["tf.random.set_seed(42)\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ZzZfGT82cbfP","executionInfo":{"status":"ok","timestamp":1715769758497,"user_tz":-60,"elapsed":1019,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"outputs":[],"source":["# 2. Load and Preprocess the Data:\n","\n","#Load CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# One-hot encode the labels\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n"]},{"cell_type":"code","source":["# Normalize pixel values to be between 0 and 1\n","x_train, x_test = x_train / 255.0, x_test / 255.0"],"metadata":{"id":"Qf58DEuR8goE","executionInfo":{"status":"ok","timestamp":1715769798146,"user_tz":-60,"elapsed":915,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CtCaf40fcbfR","executionInfo":{"status":"ok","timestamp":1715769799797,"user_tz":-60,"elapsed":2,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"957b2dd6-bdd2-40b2-911d-053addea0220"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((50000, 32, 32, 3), (10000, 32, 32, 3), (50000, 10), (10000, 10))"]},"metadata":{},"execution_count":14}],"source":["x_train.shape, x_test.shape, y_train.shape, y_test.shape"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"eau8wS7qcbfS","executionInfo":{"status":"ok","timestamp":1715769802234,"user_tz":-60,"elapsed":440,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"outputs":[],"source":["class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"vqP8WgyxcbfS","executionInfo":{"status":"ok","timestamp":1715769995610,"user_tz":-60,"elapsed":447,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"outputs":[],"source":["def show_random_images(n, a=None, b=None, figsize=(15, 15), x = x_train, y = y_train):\n","    indices = np.random.choice(np.arange(x.shape[0]), n, replace=False)\n","    images = x[indices]\n","    labels = y[indices]\n","\n","    if np.max(images) < 254.0:\n","        images = np.uint8(x*255)\n","\n","    if a is None or b is None:\n","        # Calculate a and b based on n\n","        a = int(np.ceil(np.sqrt(n)))\n","        b = int(np.ceil(n / a))\n","\n","    plt.figure(figsize=figsize)\n","    for i in range(n):\n","        plt.subplot(a, b, i + 1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        plt.imshow(images[i])\n","        plt.xlabel(class_names[np.argmax(labels[i])])\n","    plt.show()\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":670},"id":"XUW-33PAcbfT","executionInfo":{"status":"ok","timestamp":1715770010849,"user_tz":-60,"elapsed":1218,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"c4211d2e-9640-4542-fe6e-40d5fba04ca4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x1500 with 4 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAABJsAAASqCAYAAAD+0WoVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACFNElEQVR4nOz9ecyl6X0eZv7O9u1L7V1dC7vZzWarKS6SKdIiqcS0ZUeJrFiacRKPkUEsRHCQZKKBoCS2g0Q2IjiAxnASaGAg/iOKbc2MMANMElsjr7IkUxRFLaS4k81mk71Ud1VX1/bVt599/pC7p2kynqpzP2KR0nUBBETy3Of9nfNuz3t/p6nOfD6fFwAAAAA00H3QAwAAAADw+4eyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM/17edFsNqurV6/W5uZmdTqd3+uZAIBvUfP5vPb29urChQvV7fqb1rcC6zwA4F7czzrvnsqmq1ev1uXLl5sMBwD8/nflypW6dOnSgx6De2CdBwDcj3tZ591T2bS5uVlVVe9+7x+ufv+eIl/j7t07C+XeaLk7i/Inl+bxDJdOrkX5M6ey/Ont9ShfVbXUHUT53vJqPEP1elH8zs7dKD+e5MfCie3tKN+djuMZhqNhlD8+zvIrq8tRvqpqWtMof3R0EM+wtb2ZvcE8+wyjUX4s9O7tcv6/nQ/PyaqqjfWNKL++ll0fq6r6g5UofzwcRfl5p8EvebrZvhyNss9QVTWZL/7rluPhqH7i//r/eH3twDe/1/bV/+Vnfq5WFjwPrz7zyXiOmy98McpPp9m5U1V17tJbo/ylNz8Z5U88lBe0K6vZ9/DsF34znuHFr3w2yk/2s3t7r8GxsHliK8r3l/N72ru/+/1R/rG3ZMfz8W7+/PaFz386ys9m+T1tPDmO8k9/4fNRfu/urShfla/5J+N8nXfn9lGU3z/M9kNV1WSaHQ9nzpyM8idO5s/is/l+lJ9M4hHq+GjxZ+HxeFK/+I9/9Z7Wefd0JX7tJ9X9fn/hsqnFg0yvm/20u9/LC4alQfY5lgfZzW9lKSuKqqqWetl79JfzGaqXfQ9H4ffQ7ebHwkr4PXSzfqKqqjqVFbA1y4ZocTxOw//puFmDBWW6L2uefYZu5cdjr8ISucE1ejX8HldXluIZBoPsPdJ/guiboWzqNfinoJKy6TX+caxvHa/tq5W1tVpdW2whvbySFb1VVUtL2fnbomxKP8dqWJqvhaV9VV42razmf1RcXs7+GNUN/wjTomxKP0N/Jf+D3Np69mC7EZb+/Vn+x7C1tex4ms3y9clonN2Plpeza9OwwXp5Hq75O5V/j/1+djws2iN8lU727DIIn8WXWjz7zLMZWiyvpg1+eHEv6zz/YwoAAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAz/ft58dNPf6E63cX6qZ2bNxfKvdGplSzfOR2+QVWdmW5mM6yei/IHs9tRvqpqfzqP8vPOUjzD4fEoyx8No/x4OovyVVU3e50ov9LP9kNV1WSSfY5e974uAV9jeXk5yldVHR4fRPnJLDuWqqo6x6ejfLeXbX88zI7nqqrVfnZ92x/m3+Pt6STKr62txzN0uoMs38vyteA98o0Oj8dRfjLO8lVVvf7i5/ZwnB0HPDh7O3cWvh6dPnEq3v787ENZvr8Vz/Dwmx6L8tNZdv51Z4dRvqpqdpidg8d3bsUzzI+Oo/zFM9l6+U2X3xLlq6ouv+WRKH/h4qV4hnPnsnNiMMjWaZMTa1G+qurypfPZDJN8fXJ8fBTld+7sR/mbN/Pnt/5S+iAcLlar6uTp7HhaWc/2Q1XV3d07UX55JXv2mc3zNc4gWGNVVe3e3YlnGA0Xfw6d3Mc6zy+bAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM307+fFK/1Odbudxba0vFjsjR45vRLlH31oO57h3NlTUX51bT3KdzoLfv9vcDQ8jvLH42E8wzz8HEurq9kAk3mWr6r5LPsetk+txTNMxtnnWBpk3+N0GsWrqqq3lF0chqPseK6qGk+y43Et/Az99fB4rqqVcIZJ5yCeoTufZTNUfn3rhW+xsZ6dl/sHh9kAVTWejKP8orfpN9rbvbtwdjRucGHgwRiPq/qLHX+jYXbcVlUdHo6i/KNvvRjPsH+QXQtH4+yedOpMvlbtD7K/JT/xxFvjGd7/3d8V5S8+dCnKb2+fjfJVVeN+di1bW8kffvrhcrUzmUT5o4P9bICqGo6za8Paar5ePnniXJR//LG3RfkvfOGLUb6qqjrZ9zgc5uuT7a2TUX6wFI9Qd3evR/l5ZfeZ2Sx/hrxzJ7vPHB02eBYPPsZkeu/XFb9sAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZvr38+KVzrS6ndlCG9rcvK9NfV1vvXgyyp9e7cUzDGbHUX7/9ijKT2d5P3h0OIny3aV4hNo6sRHl+0vLUX7n7l6Ur6rqh4f0qc21eIa93YMoPzrO8kfH4yhfVTWvTpTfWF+PZxiPjqJ8d5odDIPl7HiuqppOs33R72X7oapqOMxmWBrkF5fuLLu+DffvZANM51m+qpbDW9Vktth9+o3uHgwXzo4m+fZ5MCbHxzXpLHYt6Eym8faXl1aj/N2bN+MZTp+/FOXf9O1vifLnLl+I8lVVg/RaOsnv7eNJtl5++tqtKH/4lRtRvqpq3M3W7F/8zKfiGd7z1Nui/L/63vdE+fk8v6ft7t6N8i++cDWeYWmwkuWXtqL8mbMXo3xV1YtXvhTll1by5479o+y5YXc3v0b3B9l6dWsr+x6Ojg6jfFXVNFuq1qTBOmt5ObhP3MdlwS+bAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM307+fFJ5Z71esu1k+tLi8vlHuj7fXVKH92axDPMJ1Ns3y4/V6/F75DVS24D18znI3jEfr9+zr0vjY/n0X56fAoyldVzXvZ9/jqqzvxDNNxdkTtHR5G+cPpKMpXVW2sbmVvMEzPqqpeZcdTtzPPtr+8EuWrqo4OjqP82iDcD1XVn2ffw/FxfjwdjSdRflbZZ9jZz/ZDVdXOYXaN3T/MvoOqquPx4te3yTQ7n3hwhkeH1Vnw/rqxml/Htk6djfJ/6F3fEc9w+bEnovzeJDv/vviVK1G+qmo3vLfv7+zEM9zauRXlr71yJ8pvbWfHUlVVdYdR/Bf+X/9zPMLg38nWmn/kfd+TbX+Qr/nPn7+QvcH8ZjzDzp29KP87n/h0lO8P8ufg9c1snTaZZuubqqrR/k6UDx+dqqrq7NlTUX4aPrvcup0fj91ai/Lpc3RV1YkT2wtnx+N7vy74ZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADTTv58Xn9leqX5vsX5qc9BbKPdGKyvZe3R783iG1dXVKD+eTKP8rDpRvqpqPh9F+dEk/x6no3GUn82z/HyafQdVVfP+UpTfGx3EM0yn2TlxOJ1F+UmYr6raO8j25cu38+9x0M0+x9Z+dl6OX7kZ5auqju4eRvk3nXlLPMO5c5eifGfzbjzD8M6tKL+/nx1Pd/eOo3xV1c27R1H++Sv59zjt3dfy4KvM5vk9ggdjeblfy8uDhbLj3ma8/aPVjSj/3G527lRVffLXfivK3761H+Vfvno9yldVDXrZPSm9J1ZVDSfZOuv4OMs/fHbxa9hrXn3lhSi/tZytE6uq9nZ2o/wzzz0X5R9++EyUr6oaDLJ98fDl8/EMF8L3ePGVK1H+i5/J8lVV5x4+G+WffzFfa9Y4uzbMRvm1ZdrPnqVXlpaj/HJ/sXvkGx0dZ59ha2srnqHfX/x7mM/uvQ/yyyYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGimfz8vPn9mrZb6vYU2tLU0WSj3RhtrS1G+Mx/HM1TNwxlmUX54dBjlq6q61Ynypze34xnW11ei/O7dm1F+e2sryldV7R1nx9MLL2efoapqf7jY+fiapexwrItr93UJ+br6g6Mo//ytnXiG4Tz7Hged7LqwvbUZ5auq3v+274ryu9em8Qzzw/B7ODOIZxgeZsfk/n72N5jlQf4ZLp/Pjodz5x6KZ7i+e7xwdjKd1YuffSmegW+81dVztbq6tlD21Z18nffslStR/vOf+2w8Q3eQXUOmw2xtcLR3EOWrqnrd7OZ+NNyNZ9jZy95j72A/yj//0heifFXV+mp2LX7y8SfjGWoyiuIf+fA/i/KPvPnNUb6q6q1PvjXKnz6dP3csr2Tn9fbWcpTvTu5G+aqqg2G2Pjk6HMYzHO3sRfnpdPG1xWtWVrN11v5u9hm2NvNnyOWV7LljNMo7jcPDxTuF8fje7/d+2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABopn8/Lz65sVrLg95iGxrtLJR7o+XBfY37NdaW1+IZhkfjKD+eTaL8iRMno3xV1Xw+j/Kjad5RjsfHUX5tYyPKX70xjPJVVV9+4W6Uv7GXHQtVVYfhWzyyutj5/Jof+le+Ixugqi49nO3L//fHvxLP8NFnX4nyk9koyve72TlZVbW3cyPKH+7n58Tm5iB7g2knnmFlJZthaSU7J9Y64XdQVZNpdmK/6fKFeIbN23sLZ0fjaf3qZ1+KZ+Ab78TJ07W6tr5Q9tkrz8Tbv/b8c1F+bZBfx+4e3Iny+7uvRvnObBblq6p29vaz/FG2Rquq6i9n18IzD52L8qub21G+qurio++K8pfD+0lV1XOf+miU73Wy9cl4Oo3yVVU3bt6K8u94x1PxDG954rEof/nhs1F+47u/M8pXVX366Rej/PB4JZ5hOMiuT7PaimeYzbM10iuvXI3yS8vLUb6qavtkdn2rOohnODo6Wjg7Ht/7PvDLJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaKZ/Py8+e/JUrSzdV+R1R7ePF8q9Ubez2LZfs384jmc4Gk2ifL/Ti/KH42mUr8obxqPxKJ7hxMmtKD+azqP8V166GuWrqm7vZvti3l+KZ+j1sr25tZJ9hnP9vShfVbVyexjln9g6H89w7VT2PV7feTXKDw/zc+oTzzwT5buTWTzDeD07r2v7oXiG6mb3ie3ttSi/OcuuTVVVx6PsXjUf7cYzPHp2feHscXif5MF57rmP1/LKykLZp7/8bLz9q9e+HOWnewfxDJvbix/7VVVPPvFolH/7U2+P8lVV124cRfkXbuTf49nz2fX8kcffHOU3T5+L8lVV1+9k38P85nPxDC++8GKUv7FzK8o/9bYoXlVVf+KtT0X5g/3seK6qmoWPT/NRtk773G98NBugqp548jui/EMXT8Qz/MZv/WqUf+V6vj4Zj7M1xvFRti/v3MmffVY3TkT52Txfsx8cLn59m0zu/YTyyyYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM/37efGJ02dqdXmw0IZObqwulHujbnexbb9mZ/dOPMP4YD/Kd6fTKD+rWZSvqpoP7mu3f42NjZV4hnFl7/GFrzwT5Q+GB1G+qmplZTnLL2X7oapqdX0typ/sTaL8x5+9HuWrqiaj7HsYbp+PZzh7MjseO7UV5ceT4yhfVXU4OoryB4fzeIbRJDueOuNRPEN1svigm73BvNvLBqiqQT87JybDYTzDfLr48ZBkebB++yO/Uv0F1wj9h56Mt//4U++I8qujfI301NueiPJPvvVSlJ8e59eQeTe8H9TNeIb+ILuv9nonovx4kq3RqqoO9m5H+e1Rdk+sqpqE19MXX82efVY2Xo7yVVXbWyej/GOPPxrPMA9/X3G0cxjln/7NT0b5qqr5UXZ9e/v3/evxDO9452NR/uhju/EMX372+Si/trYR5bdPnI7yvyvrA3YbdBrD4eLH9GRy7/P7ZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADTTv69Xd/tV3cFCG+oMFsu1tLySz7BW61G+H/Z73W7eD45rFuWXV7fjGW6+shflD2/eifKPnVqJ8lVVw+Msv7K+Fs/w5OMXo3w3/BCTXn5O7e5m+7LfuxvPsLmUndenTz4e5R9/4k1RvqrquRd/O8o//czL8QxL/WGUn8/34xkmk/u7rf2Luv2lKD9Yys+J2Sy7Rs+qE8/Q6Sx+r0myPFg3Xr5VvV5voex3vutPxttfXj4b5U8tNvpXefjCVpS/vZOtb648ezvKV1WNZstRvtuZxjP0+tl1bDrP7icV3guqqqbDoyg/n2bfQVXVxvaZKH9r/yDKd8P1UVXVbD4P3yHNV4WPPrWxkl0XHr1wORugqlZ62ffQrXyN9Y63vznKnzhxIp7h54/+SZR/5Vr23HHx3IUoX1U17WTPX4NBfn3b3d1dODseT6rqmXt6rRUhAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA007+fFx8fT6rmnYU21BkfLZT7apMofXCwG08wGmf93KS7EuX3D/eifFXVbvgeFy/f12Hzdc0n2QyPnFnsOHzN4xcGUb6q6vA4m+HiW98Vz7A0P47yd+6Oo/zqidNRvqqqbvWi+OXzD8cj7BwcRPnHvu2JKL91ci3K/+57PBXl79zIry137t6N8oOl9XiG7nw5yo9n0yg/m0XxqqqajrN7XTe7NFVV1Xw+fyBZHqzV9ZPV7y92jx802O07O69G+eVTJ+IZDifZSXyc3ZZr9eRm9gZVtTwLLwLH2XWwqmoeLhWPx4dRfmU1X6t2O6MoP+vmM2ycvhDll+a3o3xv9WSUr6qaL2XrvFknOxaqqjrTbH3R7WX7crC+FOWrqlY3sveYDPN13q2Xr0f50+tn4xl+8Pu/L8p/7FPPR/n9o+y6UFV1PLwR5YdHea9yYvPEwtnR6N6fH/2yCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANBM/35ePO1Ma9pZrJ+aTycL5b7qPebzKL+6shrPsLG5FuWv3jiK8s+9dCPKV1X1B9n3uHT9ajzD8fXsczxxbhDlv/eDT0T5qqovv3w7ym9ePBvPcOb0+Sj/6o3rUf7EifUoX1XVnWX7cqnbi2d49cbLUb6/shPlb+xci/JVVS9f24/yg0F2bauqOrE1i/JHR9m1qapq3s/+htLpdqL8bDaN8lVV3U42Q6eb/x1pmu8KvgWdv/xIDQZLC2VbHHfHx7tR/vrufS1rv66lE2ei/Hiy2Pf3ms4guydWVR3tZ/eD8Tzfl/3+cpSf9LL82tZWlK+qOnd6J8rPb2dr/qqq0Th7furMsn25upo/O6XLtNk8f4acTrN7c3eQfYh5Lz+n9g/2onxnlq3RqqqWw+v8bvjcUVW1unYqyv+r73tnlP/il1+I8lVVn/38K1F+f/cgnmFpsLJwdnwf1yW/bAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGb69/Pi7e31Wl1ZWmhDk/5kodwb7e8fR/n5eBrPcHfvbpR/4cXrUX5/fz/KV1WtrmQd47XnduMZHlrwOHrNxYuPRPkTF94c5auqBnuz7A1WBvEMl9713myEV16O8quTG1G+qmpa2Xl9cJDlq6oeXjsb5UfT7FjorG9E+aqqS+sXovzmifPxDHu3Xonyr16/Fc8w7mTn1fFomA3QnWf5qlpfXonyo6P8PjFYWvx7nFYn3j4PxrzTq3mnt1B2PM7XeYd7e1F+eXU1nmFv93aUHx1n15DD3ew7qKoahKfg5vpyPMPZk6ei/Nap9Wz7J/JjYdrfjvJHy/k5cfuR7N4+nF7LBhgfZvmqmk5GUX42y+8p0264Thssdl18zYlTJ6N8VdVsmu2LaYNr9PZ2dl4tdfI10s7eTpSfj7M10nc8la+XT2xm19hf+IV/Es9w4/rNhbOTyb13Kn7ZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGimfz8v3r97uybHg8U2NNpbKPdGg07YjfXiEarfy97kcP9ulD+5uR7lq6pOrK9E+aM7u/EM5y6cjvIX3/lHovxnXxpF+aqqZ57N3uP9D5+KZ9jZyWZ46PF3RfluHUb5qqrR8EaUPzGfxTPsvnoryq+OxlH+4VMNjoXpcpQfvPNkPMPRzrUo/5F/8PPxDC9dyY6n3tJi97j/n06YrzqaZ/lxg78jdceLH9PH40m8fR6QyWjhQ7g/y++r29nypC5v5+fftz12IspvrKxG+V661q2qg92dKH98mK1Vq6pW17P74pNPZPfFy49civJVVd3BI1F+f2cnnuHyww9H+SefezXKb50KT8qqOnVyK8r3+0vxDLPwvjoPnyFX1teyN6iqyXF2b+2G30FV1aCbXZ+OaxjPcPrMRpTfP8yeXQ52XonyVVUXz56N8j/0b/5r8Qx/9+//04Wz4/tY5/llEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANNO/nxd3O1W9zmIbmh7tLxZ8g3ktuPF/rluTeIZppxfl74yz7e/uzrM3qKr5cBTlH95ej2d4zx/9o1H+0pPfHeX/l7/1P0X5qqrz6xtRvjc6imd4+StfjvLnH3tblF85/ZYoX1W1Pt+L8oe3X41nWJ2djPKjo8Mof3Mvy1dVnTj75ih/+vyj8QxH+1tRvpvFq6pqunQc5Tvd7D4zHmfX16qqzmSa5edZvqpqMrmv5cFXGU/z+xQPxgfe+x21urK6UPaxt70r3v7Vl1+O8hcvnIpneOsTj0f582fPRfnePLsGVVXt7e1E+eE4vyel19KN9WytubGxEuWrqnpLi50LrxnM8vvB0cGNKP+H3v5IlH/0rY9G+aqq8Sx7+Jk3+G3EZJY9A84XfQD+53qDxe+prxkfZ/fW2Th/Du72s33RWcmvbxXOMBxnx2O/N4jyVVXT0U6UP3smewatqvqef+U9C2ePjof1v/78r9zTa/2yCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmunfz4s789/91yKm4/FiwTduv5t1Y/0G1dr8KPscnVm2/VOn17I3qKrza5Mo/4e+663xDE+9/7uj/J1X96P88uRulK+qeuzSpSg/Sw+Gqjp/7myUnxxnx8LhzijKV1WNJtkM46P7uox9XdPaiPJffvmlKP+Zz34syldVvf+7s31x+vzpeIbdvVej/CC/vNWZR9ej/Cy8z0xH0yhfVTUZZvvy7o2deIbh3uI7YzjOvwMejO/89rfW+vpi59C3f+e74u0fvf3xKL++vRXPkN6Z551OlO/2BuEEVafWz0f5eYP1cvoWs1m2JybjbG1RVVXhs8tweBSP8Phb3hTlV5eye+LRQb5ennfDdVonX+fNF32A/edm8yw/Da8LVVWzWTbD6Cg/Hqez7Hjq9vPvoRteXfZuHUb5F567EuWrqj7wPd8Z5Q/He/EMayuL74vO/N6zftkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaKZ/Py+eTaY16y3WTx0NZwvl3mhpfSPK9/uDeIZedxTl33L+ZJRfWc37wUcfuRzl3/U9fzSe4eEn3xnlP/nRvxXl33Q52w9VVee//R1Rfuns4/EM/bXtKH94vB/lj3b3onxV1fWrV6L8nesvxTNMx4dRfnVzJcqfOZNfm65c/USUf+jhi/EMk8PseJofDeMZOgd3ovx0fhTl5515lK+qWl3Ojoel8/nxtLvcWTh7PFo8y4O1sr5eq+vrC2U3Vpbj7a+v3dey9Gv1e/EMs/AU7nSy478b5quqZvNszT0b52v22Tz7IjvdbL07qfwzdMNdMe/ka/aNE6ei/GSafQ/TWX5O1Sz7Iuc1jUfopjtzmuWnDZ5B5xVenCbZM2xVVWeW7YvlBsfTYJqdV+vH2Qzz69k6sarqxleuR/lLT16KZ7jZDdbs3Xs/Fv2yCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmunfz4sHvX4NevcVed2dvcOFcm80Pe5E+dW11XiGXnce5c+dXovyV67tRPmqqsf/0L8e5S+9I8v/rpNRerx3EOW3N7ejfFXV2bd+R5Q/6J+KZ/jcJ347yg+Psu9xd3cnyldV3Xz5xSjfm47iGVZWFruuvebimy9G+Xe+9S1Rvqpq0luP8oPeiXiGwdI4yvePj+MZDl94OcrPJtMoP2nwJ5z9Xi/Kr53OjoWqqocunF44e3ScfYc8OBtbJ2tzY2Oh7Lw3iLd/OMyu5/PhMJ5hGM5wsJ/dV0fj/J42HGbX4slkFs8wHmczjMPv4fAwf+44PNiL8pNZ/j1unsrWq5vbJ6L8ic0zUb6qamVpKcpPZ/k5UZ1JFO9Wlt/cXInyVVW3Xs2+h+Oj/XiG2Sx7futUdixUVc2m2XV+a3M5yj/ypoeifFXV0WF2n5jPsuOxqmp7c/G14uA+1ql+2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABopn8/Lx4dD6s7my60obXl+9rU19VZ6UX5QXcSzzCfZu+xupF9hj/1Z/5UlK+qev+/8b1RfuvMQ/EM17/yhSjfC/flzt7dKF9VdeP5L0b5q3uLnUtv9M/+7t+N8hurgyh/PNyP8lVV5x/ajvJbm+vxDM+9dCXKj8Lj8dSFR6N8VdVb3/Hu7A2my/EMt3deivKHx514hjtH2b7ozLN71fHRLMpXVe3P51F+vn8cz/DUicWzx6N48zwgf/8f/GKtrKwslJ0OPhxv/86d61F+/+7NeIZudvrVcJidANevZ99BVdV0ln2IU2fPxTOcPHM6yi/3smvxwe2dKF9V9cyXsrXq7n6+Rrr85keifG+QrfO2NrP9WFX15je/Kcpfunw+n+Gxi1H+1HK2PtlcyfZDVdVseyt7g172DFpVNQ6fg3v9/HcuvXBfPPTomSi/spWvl8fz7BmwtxSPUKdOLX48LS/f+/Hsl00AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANBM/35ePJuPajafLbal2XSx3Bt0Jgtu+5+bzMf5DJ15lF9Z3ory3/Hud0f5qqrlwSDKf/6Tn4hnuHP1y1F+ODyO8nt3bkf5qqorz34+yu/PV+MZBtPse9jo96L81sp6lK+qOntyO8pfu/5KPMNknF0bDvf2o/yV516M8r/rc1F6f38vnmCln10fJ8vn4hluTbJr7OrqSpRf28zP69X+cpTfO9yNZ5jMJkE2v9/zYPzKh3+z+v3F1ggnLj0Zb38+za6ln/j1X4lneOTSpSh/5vTpKP/ySw3uaeE5uHbqRDzDqJut2a+/dCXKf+973xflq6q+453fHuUPw7VqVVV3cF+Pal/juRdfiPLPfClbr1dVfeaz2XPDie2NeIY//W/976L8B779rVF+aZ7/vuPSw5ej/KiXrfmrqjrdTpSfzbN1YlXVuLLrW7ef5ZdPZOvEqqrVbnY8zHqjeIakDejfx2XJL5sAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKCZ/v29fPbP/3X/ZpPRQrk36g/Wovx0Mo1nGNUkyj+0fTLK/+Of/4UoX1V16qHPRflzD1+OZxgd3o3yg8FylN9Y34ryVVX9bi/Krw8G8Qznz52O8kd7d6L8ai/bD1VVt27cjPLjUX5eb66sRvnR/n6U/9InPhblq6quPf1MlB9OjuIZapCdE9PwnKqqWr+0Hr5Bdq/qLh9n26+qlVl2nzlZ2fFcVfXUt7954ezh0biqPhXPwDfeD/1bf7ZWVxdbay2feyLe/uHeK1H+S5/Jj7uHz2drnG43+zvu6kq+PhnNsuv5W9+e78uTD5+L8odnsvXyD/wbfzzKV1WtbWbX0oNhfj+YdbL8ZL7Yc9trjif5Z3j11dtR/oXnrsYzrK1l59UrL92K8s9/7ktRvqqqe5zti6+88mo8w3v/te+K8o88eiGeYTzN1kjdlaVsgEH+3NEJ13nVyWdY6ix+bVgazO/5tX7ZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGimfz8vns06NZt1FtrQUr+3UO6NVvqz7A26i83+RvPeepSfjcZR/ubNV6J8VdX+jew9Vse78Qyzyo6HUydPR/kTF85G+aqqyXQY5V++mu/Lec2jfLd7X5eArzGaTKJ8VVWvM4jy6ytr8QyT8NLSS9+gk+3Hqqrp6G6U7y54bX+j3cM7UX60fBTPsHkhOy8PVnei/N5sFOWrqo4Psr8Dnd56LJ7hzLnFr7EHB/l3wIOxPOjW8tJix98zT3823v7u3ey+OJ/n19LxKDt+9/cPonynk1+LV5az++r4cC+e4e6NbF9cf/FKlP+H//gfRvmqqjt72fdwdz+7L1dVbW5tRfntk6ei/PrWcpSvqnrppatR/tyZi/EMK1vnovyH/352PN3+0qejfFXVNHyGfPaV6/EMLx1k58QTTz0Rz7C9la37t09uR/nVtZUoX1W1vZ5dowcrea+ytrb4uT26j+cev2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBm+vfz4m5nubqd+4q8bmV5daHcG81rEuXXV9fiGdY3z0T5w/FxlD+9uRTlq6r64fc4uns9nmHWzT7H4WAW5R966M1RvqpqNhpF+SffeSme4dd/5Zei/Gh+GOUHnU6Ur6o62s9m2NrcimdY6i92XXtNr5Mdj/vH2XWhquq5a3ei/M5Odl2oqhp2DqL82bfmf/+4eCK714zm2bXpzs3seK6qWjoeRPn1i6fjGY4Op4tnjxbP8mDt3b5ek6PFzqFf/nt/P97+lVdeivLd8VE8w6c/vZu9QXhfnEzya3GF96Rf/IVfjkdYGixH+e/4zj8U5UdLm1G+qmp3mF3Pv/Liq/EMt259IcqPjrNj4eorz0f5qqrnns8+w3d957vjGf7P/6cfj/K/9RsfjfKTu7eifFXV7nAY5Y9qHs/wlY9difIf/vi1eIb1/jjKD5Z6Ub63nF3bqqo217N13qVHHo1n+ME//X9YOHt4eO/Hkl82AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJrp38+LB/1OLfUX66cOh8OFcm/UW1mP8rPecjzD4fgoyvcG8yi/vLQa5auqBoPse1xa245n2N7KZnjlxvUof3jxUpSvqjp3+S1R/uVXb8YzfPt7PhDl929cjfJfeeZzUb6q6mB/J8r3e9k5WVW1vb0V5Ts1i/LXXs72Q1XViy/cjfLd5eycrKraemgtyp89le2HqqrO8XGWv519Dyfv3Ndt9eu6eO5UlL90Ir++Pfv5VxbOHh2P4+3zYJw/91CtrS12Djzx6Jvj7c/Da2m/m+WrqnqdTpTv9rK/485n2TqxqmopXC/XYCWe4cKFi1H+g9/3fVF+cy27H1VVba+cjPKf/+yn4hmeefbLUf78xUej/PE8/11CbzXbF5995ul4hs8/80yUX3v0qSh/9Wp2LFVVnTyRvce5paV4hrWN7Dn09isvxDPcevnZKH/jZvYMeTzNr9HjWXafubaTrzXf/72Lz3B0dO9Zv2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBm+vfz4nOnu7W2slg/Nb51a6HcGx1NZ1H+4CAeoebdaZTv9+/rK/8aW1uno3xV1dJgEOWPDnbjGVYH2fdQoyz/sV//9Wz7VfXYk9ej/EsvvRLP0O12ovzacnYs9HrLUb6qanV1Pcof7B/FMxwdZe8xmYyi/MZq/j2+/zvfGuVXNrfiGSa9SZSfjg/jGY6uHEf57t5KlD+3thnlq6q+863fns1w4qF4ho9fe27h7PEoOw54cO7cvFPHq8OFst/9h98fb//9f+SPRPnl5V48Q7+X/R22283ys3m21q2q6lX2PYxH2Vq3qupolF3Pb720+DWoqur28TjKV1Xdvnk7yn/l2S/HM1x9NVsrbpy7kA2wnN0Tq6o6S2tRfjRZ7Jr0Rr/4oV+L8o88/o4of/nUxShfVbXSzZ591gb5WnN4vBflv7L7uXiGjXC9Op1na5RX7uxH+aqqM2cejfKH4/w+8csf+q2Fs+PxvT/3+GUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoJn+/bz40qWl2lgdLLSh7c7KQrk3evbKYZS/fmMezzCaLkf5jY37+sq/xsHh3ShfVTWd7Uf5XoOO8vaNW1F+b38S5Y/H+ffYm2fvsblxMp7h+iu3o/xLB8dRfjbvRPmqqofOno7yndk4nuHOzp0ov7yeXRdObG9G+aqqpV52Xg5H03iG6i92f3jNwTC/toz2sxnWZ9kMb7l8PspXVV04n50TV166Hs9w68bi99vhuMGxxAOxtrZca6uLXc9u7Wb3k6qqT3z641H+3Ln8vvrQuTNRfjzO7kl37uxE+aqqOs72Rb/BffXimy9E+csns/viy89ci/JVVQf7wyh/7qH8frB2+kSU761sRfnDo/y8fvjhN0X5V66+FM9w81a2Zn/4wkGU78zzZ9D9YXhe9rO1alXVeJbd35dX1+MZljvZs8fo1o1sgG62zqyqeujio1F+NBzFMySH5P1k/bIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACa6d/Pi7dODGpjbbDQho5uHC6Ue6OT53rZG6yvxTPcvD6M8sejUZTvL21F+aqqcISajafxDONp9j3ePboT5ddXl6N8VdXx4XGUPzq+Gc8wCvfFNMzP5+E5WVX7u9m1YWtrNZ5ha2s7yh8dZZ/h5q3seK6q2thYj/Kdbv63h85kHuWX+vm+XF7J8ktL2TH96FsezQaoqqPD7Hv81V/9fDzDp595deHsZDqLt8+Dsdyf1fJgsf03PN6Jt//rv/5LUX4+zu7LVVVba9l1aDyeRPnjo6MoX1XVD/+W/Mijl+MZ3v7db4vyj7/pQpTfufJSlK+qeuVOtk5barDWfPz0+Sh/48Z+lH/Hk2+P8lVV3/6OJ6P8//P//rPxDP1aivLjg+zaMhrl16b5JHz+WsmuTVVVveXsmH70zY/FM7x65YvZG3Szdd7qen5eP/XUW6P88WF2XldVXX743MLZ4fDej2e/bAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGb69/Pi3kq/+iv3FXndytbSQrk3OrWRdWP9o2E8w2B1FuV37yz2/b1umveDqyvnshEG2XdQVTUd7kT5pbXsexz08+Ox11uL8sN5/j2OxqMoP593onxnHsV/d4bRcZSfZvGqqhr0B9kbLC1H8Z07d7LtV9XRaBzlt09sxTP0u9n1qdvgvDysSZS/fnMvyt/Zz7ZfVbV3cDfK/9N/9nQ8w/XDxbOzWYMLAw/E4fFR1aK3hfD8r6r6vn/jB6L8bHQQz9AbZ+fwbJrd2+e9XpSvquqF19KV9Wx9U1X1ys5RlN/beSbK3z7Kr8WdlZUo/8VPfiWe4dZHb0T5x978ZJR/z1ueiPJVVaOjbKG2Gq6xqqrm42yNdBh+hm4vfP6rqlm2ZK+jWf7c0Z9m59Ujlx6LZzjevxXl37a1HuV/6+OfiPJVVVdf+GKUPzrI73Xzw8WfPe7n+dMvmwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADN9O/nxQf7/erMBottqbexWO4NNtaPo/xgdR7PsL68EuW3t2dRfn/3KMr/7ntcz/KH03iG8XH2HptLp6P8ymDB4/gNJsNhlO/38653KXyLwXIvync6+WdY27ivy9DX6GbxqqqaTCdRfmk1G2LrxFqUr6q6fXsvyu/Ns2tTVdXWqey8PJyM4hm+9PytKP/0Z65E+YdObUX5qqqHLoXHQzffl2e2NxfOTmezeuFOdr/mwVhfH9Ta2tJC2e18iVWbZ98a5YfhfbmqaiX8O+xSZ7Hv7zXz1dUoX1W1vOA+fM3seD+eYW9vN8r31rJr6bnHT0T5qqrH125G+S899+V4hupk67TB2nKUf/nai1G+qur0mZMPNF9VNTo6iPLD4d0of3CQ3xOHh9l5OR4exjP0V7L1yUMXzsYzvHAte469/mJ2Xh7vZ8dCVdWXP/fJKH/6dP49zk+eWjw7vvd1pl82AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM/37efHVK1VrK4ttaLizYPANNs9OovzK6jieYXsjy586dV9f+dfYPzjMBqiqnZ3sPe7cWopnuHMry/dmvSg/m8+zAapqOp1mbzAL85W3xZ1uJ8r3+tnxXFV1NM0+xTy7LFRV1WCWXRsmh7ej/PQoP6+n/UGU39nPZxiFh/Tt3aN4huefzS4uO7cOovzoID+vz2+fj/JPPXIxniHZFePprH7n+eyc4ME43H+2arrgem2W//1y0MkWWdev341n+NLnn4/yK/3VKL+0fSLKV1WdOXcyyl84sx3P0O9mx8Pp7dNRfjqL4lVVdXx0J8qfO7cVz3Dxwqkof+2VV6L8M898IcpXVT06enOUHw6H8Qx7e9m14fDwepTfvbsb5auqhof7UX46ytdYveX1KP+5z56JZxgNR1H+3LmHovzFd749yldVnTubzXDmbLZOrKpaCfbl8fD4nl/rl00AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZvr38+Lp4HRNB8sLbWi89F0L5d5oOBtG+e7kZjzDynYnyp84uxLlT3YnUb6q6tThLMrv3F6NZ9i52YvyRwf3deh+jelkKcpXVdU862pnk2w/VFUdHx1H+aWl7Hvo9bP9WFW1d5x9D0f72XdQVTWYj6L8Znczys+6u1G+qmo8zs6J5fV5PMPKgveH15xYyvZDVdVjdSLKv+Nd61H+yXe+K8pXVT36lrdE+fd+92E8w0tX9xfODkeTqt95Pp6Bb7z5aFizBS/r3QZ/v+yPs3vK1iC/r378Nz4U5V+5nq01O+F1tKrqve99d5T/nvfla/a7d+9G+U//zm9G+YPjfG3wzItXovxXnn8+nuHoMLuez+fZc8vK1tkoX1W1u7sX5ffu5M9vB7t3onz2LVb1e+k7VG1vrkX5C29+czzDydMPR/lzF87HM1z4zndE+VNb2TpvqZc/+/TS9+jkMyTPsf3+4J5f65dNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJrp38uL5vN5VVUdHo8W3tBRkH1NZzCO8rPZJJ6he9iJ8v2D7DNUd5rlq+rgaBbmw89QVYfH2QxHx/Mo3+BQqLSrnU2y76Cq6niY7YvpPDuee9P8eDwaZvvyeJQfj/N59h79bnZAHY/yA3KYvkUn2w9VVb15L8oPx/n3MJpkx+QgnCG5T75m/+A4yh+F14WqqmFwTL62H19bO/DN77V9dXQ8XPg9xg3+fjkJryHHwfyvmc6ye/MsPO4783xtMJ6E96Rh/j0Oh9m1cDjK8qMGa4NJ+D3OwmOpqmoevsc8XOfNZvk6b1bZe6TfQdWDvx+12Hx6PE0brNnTc2I8ztdIw/D6dDzM7jOzbpavqur1wvfo5DPUfPF79vHwd9ep93Jedeb38KqXXnqpLl++vPBAAMAfLFeuXKlLly496DG4B9Z5AMD9uJd13j2VTbPZrK5evVqbm5vV6WQNOQDw+9d8Pq+9vb26cOFCdbv+af1vBdZ5AMC9uJ913j2VTQAAAABwL/zJEQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibgNfN5/P6D/6D/6BOnTpVnU6nPvnJTz7okQAA+Cb2/PPPWzcCX0PZBLzuH/2jf1R/+2//7fqFX/iFunbtWr397W9/0CMBALCAD37wg/VjP/ZjD3oM4A+o/oMeAPjm8eUvf7kefvjhev/73/91//vRaFRLS0vf4KkAAGhtPp/XdDqtft8jIdCeXzYBVVX1wz/8w/WjP/qj9eKLL1an06lHH320PvjBD9Z/8p/8J/VjP/ZjdebMmfq+7/u+qqr60Ic+VO9973treXm5Hn744fpLf+kv1WQyef299vb26t/9d//dWl9fr4cffrj++//+v/fXNQCAb5Af/uEfrg996EP10z/909XpdKrT6dTf/tt/uzqdTv3Df/gP693vfnctLy/Xr/3ar9UP//AP1w/90A99Vf7HfuzH6oMf/ODr/342m9Vf+2t/rd7ylrfU8vJyvelNb6r/5r/5b77utqfTaf37//6/X9/2bd9WL7744u/hpwS+mSmbgKqq+umf/un6yZ/8ybp06VJdu3atfvu3f7uqqv7O3/k7tbS0VB/5yEfqb/7Nv1kvv/xyff/3f3+95z3vqU996lP1P/wP/0P9zM/8TP3Vv/pXX3+vH//xH6+PfOQj9fM///P1i7/4i/XhD3+4fud3fudBfTQAgD9Qfvqnf7re97731Z//83++rl27VteuXavLly9XVdVf+kt/qX7qp36qvvCFL9Q73/nOe3q//+K/+C/qp37qp+onfuIn6vOf/3z93M/9XD300ENf87rhcFj/9r/9b9cnP/nJ+vCHP1xvetObmn4u4FuH30wCVVW1vb1dm5ub1ev16vz586//50888UT9tb/2117/9//lf/lf1uXLl+tv/I2/UZ1Op77t276trl69Wn/xL/7F+st/+S/XwcFB/Z2/83fq537u5+p7v/d7q6rqb/2tv1UXLlz4hn8mAIA/iLa3t2tpaanW1tZeX9c9/fTTVVX1kz/5k/Un/sSfuOf32tvbq5/+6Z+uv/E3/kb9uT/356qq6vHHH6/v+Z7v+arX7e/v15/8k3+yhsNh/cqv/Eptb283+jTAtyJlE/Av9e53v/ur/v0XvvCFet/73ledTuf1/+wDH/hA7e/v10svvVR37typ8Xhc733ve1//77e3t+vJJ5/8hs0MAMDX913f9V339fovfOELNRwOX/8j4v+WP/tn/2xdunSpfvmXf7lWV1eTEYHfB/xjdMC/1Pr6+oMeAQCARv7FtV232635fP5V/9l4PH79/77X4uj7v//769Of/nR99KMfzYcEvuUpm4D78tRTT9VHP/rRr1qUfOQjH6nNzc26dOlSPfbYYzUYDF7/33yqqrp7924988wzD2JcAIA/kJaWlmo6nf7/fd3Zs2fr2rVrX/WfffKTn3z9/37iiSdqdXW1fumXfulf+j7/0X/0H9VP/dRP1Z/6U3+qPvShDy00M/D7h7IJuC//8X/8H9eVK1fqR3/0R+vpp5+uv/f3/l79lb/yV+rHf/zHq9vt1ubmZv25P/fn6j//z//z+pVf+ZX63Oc+Vz/yIz9S3W73q/7ROwAAfu88+uij9Zu/+Zv1/PPP182bN2s2m33d1/2xP/bH6mMf+1j97M/+bH3pS1+qv/JX/kp99rOfff2/X1lZqb/4F/9i/YW/8BfqZ3/2Z+vLX/5y/cZv/Eb9zM/8zNe814/+6I/WX/2rf7V+4Ad+oH7t137t9+yzAd/8lE3Afbl48WL9g3/wD+q3fuu36l3velf9h//hf1g/8iM/Uv/Vf/Vfvf6a/+6/++/qfe97X/3AD/xA/fE//sfrAx/4QD311FO1srLyACcHAPiD4z/7z/6z6vV69ba3va3Onj1bL7744td93fd93/fVT/zET9Rf+At/od7znvfU3t5e/Xv/3r/3Va/5iZ/4ifpP/9P/tP7yX/7L9dRTT9Wf+TN/pl599dWv+34/9mM/Vv/1f/1f1/d///fXr//6rzf/XMC3hs78X/wHdAEaOzg4qIsXL9Z/+9/+t/UjP/IjD3ocAAAAfg/5/0YHNPeJT3yinn766Xrve99bd+/erZ/8yZ+sqqof/MEffMCTAQAA8HtN2QT8nvjrf/2v1xe/+MVaWlqqd7/73fXhD3+4zpw586DHAgAA4PeYf4wOAAAAgGb8D4QDAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGb69/Ki2WxWV69erc3Nzep0Or/XMwEA36Lm83nt7e3VhQsXqtv1N61vBdZ5AMC9uJ913j2VTVevXq3Lly83GQ4A+P3vypUrdenSpQc9BvfAOg8AuB/3ss67p7Jpc3Pz9Tfc2tpaaJjZbLZQDviXmOdvkf4V++jgMMrfvnMryldVnTx5IspPx8N4htXV1SjfW1qOZ5h3sl+RzCo7FnpRmt8vdnd365FHHnl97cA3v9f21fmzK9XtLnYdWFldiedI70f9Tn4VSn+NN5lN4xkq/B7u7u5F+ZXuUpSvqlrrZvtif3gcz9Bdy+6rK0uDeIb19fUov7W1Hc+ws3Mnyo8OszVSg6VqjUfj7A0a/GCz18+O6aV+/kvfrfXsOnv+zIkof/XVV6N8VdXhKLtGbm6eiGeYTLKj8vBgN57hwoVsjTQY3FON8y/V7y32HuPJtP7+L33hntZ597SF127+W1tbyib4ZvJNUDYNFrxQvWY8GUX5qlr4uvSa6Shf1K6urUV5ZRO/3/jHsb51vLavut3OwmVTr8E/MpkeMy1mSMumeafJjTmKL7oPW+Wr8n3RYob0PXq9/HhK36MfFhwtZkj3ZYuyaZae2y3KpnCGFsdTP3yPQXg8pduvqur1siOixTlR82yGFvsy3Rdpvir/Lu/lnu1/TAEAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzfS/URvqdvVa8PvR8PBulL/90lfiGa58IZvh7u5BPMMH/tj3Rvmt1ZV4hvTvB53qPMCt8/uF+/23rkGvV93uYteB6WQcb382nUX5ztJSPMNwMonyvX4vnqE62bX4xOZalN9aX4/yVVWjvey+OjsaxTOsDVaj/PZalq+qWgvv7RtLg3iGm0fDKD+bZ/mVleUoX1V19uyZKH/nzp14hpVwX154+Fw8Q6/mUf7cuVNRftBgrfrclatRfmmQXR+rqk6cyK5xG/klsk5vb0f5dM1eVXVwuOB1+j7u1VaEAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGb636gNzefzb9Sm4A+MFudVt5O9xytXnovyn/7or0b5qqrx0WGUH2ycjGc42r0b5bdOnYpnmFUnys872d8fXOWpcr//Vjbod6vXXew60gmvH1VVJ8+cjvIH4b2gqmow7UX5yWQSz9AJz6GHz5+L8ufPZvuhquq5Z78c5c/0t+MZzl84H+W7k/yY7nay+/LW6ko8w+ntzSg/761G+e3tfF+ura9F+V43Py/PPnQmyq8sDeIZ9sK15mQ+jvLbJ/J9eXGSXd96DdqL/iCbYbm3HM8wG02j/NbmVjzDfDxbKDeqe5/dL5sAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKCZ/jdqQ51O5xu1KfgDY16z+D3Gw8Mof/XKC1F+a201yldVrZ3YjPKv3tmLZ7h17eUo/9DlN8UzVLcXxefh5jtd13nc77+VbW9uVK+32N8hV1ZX4u2fO3cuyr9661Y8w8rycpS/e2cnnuGhM2ej/PJydi9YXR1E+aqqi5fPR/n19fV4hvFoEuWXaimeYXkpO54Oj47iGS5fyM6r+SBbay4t59/jaDSK8mdOb8cz9LvZ9zAcHsQzbG6tRfmjYXY87d29E+WrqobDaZQ/fSZb81dVra5nFUi/k32Gqqr+KDsvjg/ya8NkOF4oN53c++f3yyYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM/0HPQD8QTafz6N8t5Plq6pu3L4V5Z9//sUoPwy3X1W1ubIU5Q/3d+MZnv7UJ6L8+Ucfj2c4cf5i9gbh8RjGq6qq0+nkbwIs5NTpUzXo9xbKzmazePuj4+Mo/9D5c/EMayurUX65t9j390YPnz0b5cfjwyh/6+arUb6qanNrM8r3B/nfw2ej7Jgc9PP7Ubeb3RiPDvP1SYUfo7uSHdPD0VE2QFUNR8Mov7y8HM+wv7sX5dc31uIZptNplL91+06UXx6sR/mqqnSZNwqPhaqqvf39KN9NT6qqGu1m+3I0GsczbKwvtj/Hk3uf3S+bAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgmf6DHgD+YJtn6fk0nuDll16K8s+9mOWvPPuVKF9VdWZzI8pfOrMez3DtxRei/Gc+9tvxDN/1wRNRfm1rOxugk8WBB6tbs+oueCKPhsfx9qejYZSfdGfxDMPjwyjf7+V/x93duR3lO5WtDebTBmuLa9ei/PbGZjzDWn8pyu8O78YzzOfZOm9pJX9UG0/GWT48Lzvd/JyYTbJjctbLj+nlpUH2BtmhUFVVh0fZvlhaXsvyg+UoX1W1tpItFpeXs/O6quruzk6Yz68NGyvZmrvT68UzLLruH40n9/xav2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANNP/xm1q1uA9Og3eI/XNMENonsbDN6iqmofHQyffD51viq41+xyz2SSeYDwZR/m9w+Mo/9L121G+qup6+B7T6bl4hkvnsuPp6d/+rXiGc+cfjvJvfc97wwnyW0p3np0TnQaXp/TSEH6EqqrqpNfIB+lbefY/4Do1r86C9/ilpfz8n8+zE3gyze5nVVXD46Mof3J1PZ5h0M0uIv3uIMofj3pRvqpqaXklyo+Go3iG0e5BlF/aWI1nWFpaivKdQb4vppNhlF9dyb6H8Sg/Lze3TkT5lZXseKyq6nSmUX5vfz+eYTzKZugMlqN8i++xxtnxMDzMjueqqukoW+gt9TfiGbZOnYry43H+DLh7cLjYtif3fhx+MzxtAwAAAPD7hLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDP9b9ym5t+4Tf0emlfnQY+Qf5Xz7A3mYb6qal6TKN9p0ZN2sn3ZaXAsfDO8w5sefTTKr21uRfndg6MoX1VVnex4+OyVV+MRVvvLUb5/PIpn+NyvfyjKn774UJQ/eemxKF9V1Zlk15fOPD8n0uv8rJtfIxu8xQPT4BbBA9LtdqvbXex6Op/lO351fTXKH3dm8QxL6+tRfnowjGeoTrY8P/9Qdi2f3GpwEk+ye9r6UnZPraoa7u1H+e3zp+IZDg8P4/dInXnobJQf7mf7stcZRPmqqsEgOx5WlrNrS1XV8VF2PC0v5TN0lzai/N3w+jQeT6N8VVVvmj0DHh+P4xlq1oviqysr8Qj9paUofzzOnxtu3LyxUG4yvfd7rV82AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM/1v3KZ+f/RanfmDnqBqPg+HmGX52Xyabb+qxpNRlF9aWopn6MQ7sxPPEB9OnV48w8mTZ6L89/yrH4zyn/nk01G+qur5516I8tNJfkw/23slyq88eiGeYfrFL0X5z3zoI1H+D/+bZ6N8VdXq2kaUn+anZXXC92gwQk3yq0Oss+Anyc8mHpRrN3er11tsvRavTapqfTiL8hvb6/EMx6PsCN7orcQzXHz4ZJRfXsuuQr07Ubyqqk6uZeu0E2v597h5PlvfDLv5Mf3MK1ej/IkTW/EMw4Nshx4fTqL8oME5Md7NZjgeDuMZZuGauzfI1+z7+3tRfnKUbX80zc+JsyfWovyprez6WFX1pb2vRPnTJ/MZ0ke4rfXVeIbZeHOh3Pg+npt+fzRAAAAAAHxTUDYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAz/W/Yluad/D0avEVsPs/ileWr8q9hMp9E+S89+6Vwgqqjo4Mo/21PPRXPsLzci/LdzoM/IGfz7DNUVc3Cy8D7P/CvRPkXn3s5yldV/Y9/83+M8pOjUTzDizd2ovzy2nI8wxOnsr8ffPHDH4vyZy89FuWrqr7tA++N8oeVXd+qqgaz7HtcanBtuH14N8oPR8N4hulkulBub28v3jYPxnAyq96Cy5Tbt2/H2187PI7yp8b5tXwQ3hNXNtbjGY4Pd6P8/mF4HWywvOlNshmGe/k17OzmRpT/4peei2fYWFnL8qur8QzD4VGUP/nwqSjfmQ6ifFXV5DA7HlYaPPHuHS92T3zN8vJKPMMr169mbzDLjqeN7RPZ9qvq+Ogwyk/G43iG1ZXs+WlzfSme4fbefpQ/Hmb3y6qqzY3FrpHj8b2fC37ZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzfS/URuazefxe3TCt5g3mGE+nUT5Tot6r9OJ4ldefjHK/3/+wS9E+aqq3d27Uf79N1+NZ/ijf+SPRfnl5eV4hvS8mMUTVE2m2btsbG5G+R/4wR+I8lVVz37xmSj/T//hL8Yz7I6za8PTL78Sz3CysxrlV46zC9Rv/KN/EuWrqvqnN6J896ET8QwHO9n1aTCbxjNc230pyt/dyz5DVdXx8fFCuaPDo3jbPBhnT25Uv99bKDs53o+3v7mR3Vfnk1E8Q6+fXQdXV5fiGdLl6uFR9j2MJvlidXkle8R46sm3xDO88sr1KD8c5s8NZ86ejfKT6TieYVaDKL+2sR7lR4f5arW3mj379Lr5ffngdnZfvXuY35e3t7ai/P5hdkxPZ/nxuDzIjsfxJFtvV1VdfNPlKD+r7Hisqrqzm90zZ7P8vDpxarHrU/c+nnn8sgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQTP8bt6lp/hadrBu7c+dWPMLdO7ejfKfXiWd45carUf6jH/utKP/xz30qyldV7d7eifLD8Sie4dvf8fYof+7smXiGXi87BXf3DuMZdnZ2ovyjly5F+QuXzkX5qqof/vP/xyh/5eUvxzP85qc+HeWHB714hi+99EqUXzufzXDrs5+N8lVVh/9Lln/8A38onuHO/l6UPzzcjWcYdnai/Gg8jGeYzeYL5Y6P8m3zYKwv92rQX+w68NTjb4q3v7q2FuW74T21quqVK9ei/GSSH//rG9l9cWf/OMr3OktRvqqqU9l6d+9udh2uqrrx6s0oPx7HI1TVIErv7+/HE8zm2Qc5PDyI8vu72fFYVbW1thnlR5XvzHlnEuV73fw3Hlub2fewupZdI/sL3h/eaHNzJcr3uvkMs9ksyj/34pV4hk4/u84u9fLvYe9wsXNzPL73c8EvmwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoJn+/b18+M//df9ms+lCua/SyeJ3d2/GI3z4138tyr9w9aV4hpu7O1H+zsFelO+uL0X5qqqV4XqUf/VWi3354Sj/6KOX4xmWl5ej/Msv3YhnGI9GUf7ocCfK7+9l+aqqwX1eyf5FT73nsXiGTz77mSg/2pvHM7y0sxvl15ay4/HS9kqUr6p67mO/E+V7y/nfULoXTkX5u5PDeIZe+gbz/Do9HC52vx8exZvmAdkY9GowWOzoW1/L7utVVYOlQZTfPpGdu1VVq+Fa886tW/EMn/vCM1F+Msuug8tLG1G+qurU+skof/Xll+MZbt3M1orHk/yetns3W3NXJ7+nzWdZfmfnTpQfZ8vMqqoaDbM3WVuL76p16vR2lO802JfDSfY8PZ9la82j4/wGP1+wS3jNZDKJZ1h0ffOaaYNeY7XBPTPVHyy2Vpzfx++V/LIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0Ez/fl78hS9+pjY2NhbbUH+wUO6NxqNRlL+zsxPPsLN/N8q/eO3leIbtc6ej/Knt1Sh/+szZKF9VdePL16L8Fz77mXiGX/ynvxjlt7ey77GqqtfvRfnhaB7PMBoeR/l/9I+z/KBB5X3h0rkov3Ymvz696zu+Lcp/4te+GM9wWLMo/8yt61F+dboe5auqTk42o/yzv/HxeIadsytR/nY32w9VVYNRNsNkPIlnODw8XHDb43jbPBgXHjpby0v3tTR83XQ2jbd/8sTJKN/rZPfUqqrBmWyG82ezNVpV1S/9yoei/GyWfQ8nNjtRvqrqlWvZ2uChk9k1sKrqxPZizyyv2Xn1KJ7h5quvRPkTJ7fiGdbXl6L8djjD5vqpKF9Vtbm9HeXXN/J13uQoOx6+8uwL8Qy9frYvD4fZs/QofBavqhoNs3tFr5c/OHTC9fLqynI8w7STHZPjBmut8YLPgOPxve9Dv2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBm+vfz4t/8+G/V6urKQhs62j1YKPdG6yvrUf4HfuAH4xkm8+Uo//HPPB3PsL15MsofzY6j/IVzD0X5qqrx9aMof/fgMJ7h8EtfjPInl/Oudn07O6Y3Tp6NZ1hZn0X57RO9LL+1FeWrqra2NqL86sZaPMMH/9gfjvJ3b96NZ/jsZ78S5afjTpR/cSe7tlRVDQaDKN9/ZRLPsHcne4/J5mo8Q3f1TJR/+cq1eIbdBe/bs+k03jYPxnw+q/l8sXvC8lJ27lZV9XrZfXV8kK81l3vZdXA+yPJVVdNZ9j10u9m+aPKX6Nk4ij/yyJvjEc6czdZIl67txzMsL2f7YitcJ1ZV9cJj+tVXX47y7//D743yVVXnL1yI8pN5vj7ZvXUjyt+5eSee4dZOdo3r9+ZR/uyZ7ShfVTWbZTO0WGNsb2TPDXfu7sUzzLvZeTk6yo/p6Xix9e50cu/7wC+bAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM307+fFz7/wfC2vLC20obuv3lko90ZPvPmJKL+6uh7PcPXqq1H+hedejGfYWF+N8sPxYZTv7B5F+aqqo51J9gbdTjzDWx5/LMo/fnY7nmHz5FaUf/XVu/EMJ09lnfPDl7Pzam83Ox6rqpZmWX5l1otn2AqPhz/xr//ReIbbd3aj/PWXsuvbzWG4I6pq7W72Gc5tZedUVVW/M4/yFzdPxTOsP3Q+yr/8/PPxDKPDvYVys1l+HPBgvPTyyzXoL3Y93FjP11h7ewdR/sTyYmvUNxrVOMpP+4N4hrXNzSg/OsrWWOfOnozyVVXL3Wyt+PhjF/MZwuOhO8jW21VVS8vZ8bC6mh9P3XDNPD9a7F7wmuHufpSvqhpvZ8fT6YfzNXt3ks3wyOVL8QzLK9kaafdgJ8ovLd1XdfB19TvZe0zG2TW6qqq34H3uNdPhKJ9hJbtnzifDeIaN9cXWq6PRpKq+cE+v9csmAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABopn8/Lz7cvVuT4dJCGzo8Ploo90bLaytR/u7e3XiGF648H+VPbG/FM0wPjqN853gY5a+98myUr6q6dvVmlO90s89QVfXv/On/fZSf7d+OZ/jlX/tnUf6FT78cz3B6e7Fz+jWvfKkT5S9eeFOUr6q6O76evcHg1XiGU6cfivLvePLt8QyjH7qvS/rX+J9+5v8W5Y/2smtTVdXVnf3sDfrZ8VxVNRzNovz+zVvxDBfCe8XS6iCe4cy5EwvlptNpvfRivHkegMOjUQ36i/0dclbZvaCqajSZRvlTZ0/FM8xmkyh/fDyOZ7h8+XKU//xnvxjlB/18Xz58/myUP3v2ZDxDr5Ndywf5ZbSWlrP78lr47FNV1euF+/PofBbf3c22X1W3b2TrtHk3X5+srmTfY4t9ubU5j/K7h9mzy3yaX99WV1ajfKfBOm88HkX5rdW1eIZpeJ3dWsu/h0FvweB95PyyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmunfz4tHo+Oqmi60ocPhwUK5N3r2uWej/P/6d//neIZf+9CHonxn3olnuL67H+VvvHAlyg9mUbyqqsazxY6j1yyd345n+MivfjjKD3dvxjN8/kvPRPmD65N4hp0b2b44cXolyt94Jf8Mu3ez68vJE6vxDKNpti//2T/7nXiG1a3TUf7kmXNR/ub4VpSvqjocZsfDy3vH8Qzz5ew6vRYej1VVvRuvRvkTp/NrZK93X0uE143H4/rUxz8Tb59vvG6vX91eb6Hs8HgUb3+5vxTlh6NhPsNK9nfY7jhfJE1HR1F+785OlD/c343yVVVvftPjUX41vA5XVW2sbUb57ZP52mA8GUf56TQ/r3q97Jg+cyb7Hl99NTueq6qu3bgd5T/+2U/HM7zlLW+K8q/eyM+rq9duRPlJZdfIE1vZsVBVNajsGrm8nD13VFVN+ovd514zPM7XmrPwErd26kQ8w+7+Yp3CtDu/59f6ZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTQAAAAA0o2wCAAAAoBllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgmf79vHjr5FYtLy8ttKFxg1prd383yn/+k5+MZ7j+3HNRvnt/X/nXtdYfRPml7mL78DXz0SjKV1V1qxPlLz18MZ7h1ObJKH/n8Cie4bFHn4zyL0zvxDPs3L4V5afLJ6L89YPjKF9VdXg4jfI7t6/HM3R6vSh/3GmwLw+/HOW7S6tRftbLri1VVfOl7Hs8rFk8w3SSvcd6+D1WVW1sZ9enXi+/6c7mi51X49E43jYPxkOnH6qlwWLrlOVBfsytLbjGfM3qWra2qKqaTLM1zmA2j2fYWplE+ccvPhTlT6zl17AL505E+Y3l7F5QVbW1vhLlj7v597A0y47p3bvZsVBVtbKefY7BWvbc8cqN/ShfVXXl9mGU/+Kz+TrvlVez9eru3fx7GI+z93jbUw9H+Y2V7FioqpoeDrM3mOXXhvk8u06vLDX4HibZs0unl3cKk+li15f7yfllEwAAAADNKJsAAAAAaEbZBAAAAEAzyiYAAAAAmlE2AQAAANCMsgkAAACAZpRNAAAAADSjbAIAAACgGWUTAAAAAM0omwAAAABoRtkEAAAAQDPKJgAAAACaUTYBAAAA0IyyCQAAAIBmlE0AAAAANNO/nxevn9yqlZXlxTa0ub5Q7o1Gtw6i/M1nrsQzXN7YjvKd7lI8w97RcZQ/7k6ifGd1JcpXVS13elH+xvXb8Qwf/81PRfmHNjfjGW7d2Ynyd4+O4hn2Z1n+6OZuOEEnzFf1e9l5tTqYxzMcj0ZR/sbOTjzDtJudV2v91Sjf6eZ/v+iuZJ+hKjygq6rm4yh+cJCfl7u72XucPH0inqFmC56bnfx84sGYd7s1X/A8Xlldi7c/6GfXkMFyfg063htG+fF4Gs+wvbkV5b/jO85E+Rb3xMEguy/3+/l6eToL7wfdbL1dVbW8dF+PWl9jY2MQz7C0nK2z5rPsMwwarA0+//QXo/zBYXZfr6qqafYcOhzmMyz1suOh213sOf41806+Zp91s2vkboNnn73D7NxOnzuqqkaj7Hl8MsyvT6PhYve70X3c5/yyCQAAAIBmlE0AAAAANKNsAgAAAKAZZRMAAAAAzSibAAAAAGhG2QQAAABAM8omAAAAAJpRNgEAAADQjLIJAAAAgGaUTfx/27v3GLvO8l7A79q3mdmeGY9tnCshTiAEpySpTq8JkaqK3gL0cI2AtupNparUi5QqUpEKUhClUS9ICFBpitomQYhURQKhEqFSK2nVtA1N1bRHbQCHc0JCcYjjeGzPde+11zp/UM+xGw7M7PcjJvR5pPwxnv2u9e61vvWtb/1mzwQAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJgAAAACKETYBAAAAUIywCQAAAIBiejt5cdPvRDOYLp9qJ9VUdWcadHPZWH88SffwgsW9qfq60033cGp9PVXfXZxP1XcGs6n6iIj1r5xI1W8ur6V7OHXsVKr+qSaf1S5v5t7Hgf9xTbqHJ44eS9UvH8+dy/n5Xan6iIiNtdVU/bifH9Mbm3Wqfn3cpHvodHLz7Gzy2m6rcao+ImISuePQ7e3otvY1deo2Vd80+XP55NHlVH2dv91FbzDdeBqP8+OAc2M0nn4eO7Wavy93Foap+vXl3H09ImJc58bvcG4h3UO3M0jVLx9LrrH6uTkwIuLESm6tOp7sSffQJu/L/V7+2aWfXPevTTbTPUTyfjBaz/UwnMnfl5944kiqfrPNr/M2u7m5YdDLXdcREd3Z5Hhayw2GejRK1UdEzAxyx+HERm5uiYh44tjxVH0b+ef5aHPzS1XlF3pzU16b3R3cInyyCQAAAIBihE0AAAAAFCNsAgAAAKAYYRMAAAAAxQibAAAAAChG2AQAAABAMcImAAAAAIoRNgEAAABQjLAJAAAAgGKETQAAAAAUI2wCAAAAoBhhEwAAAADFCJsAAAAAKEbYBAAAAEAxwiYAAAAAiunt5MUnTqzExuZoqh1trk1Xd6Zdo26qfv8FF6V7OPbFJ1P1jzz6xXQPR8cbqfq9e/em6juzc6n6iIjV5niqfjKu0j3Ua5up+o3NSb6Hqk3VH33iqXQPqytrqfp2nHsPw5lhqj4iYrSeuyaqmZl0D/VGbjwNdu1K99BOmlT9tPP7aU0nNxYiIkZ1roeZ/iDdw2A2Nx7mh/PpHuaS2xgnr8uIiE5nup9HtXV+fubcOLZ8Ivq96dZaF523L73/U6u5+1Hd5O4FERF79+XWSKdO5t5DRERd57axOUrO5fnpIz77yP9J1Xeq3P0sImLQzf1M/QUH8s8Nnfnc/WRjNb/WnCTHQz1aT9XPJM9DRMTy8ROp+s//R/7567L9F6bq9y7sTvfQ27uYql9dHafqj9e58xAR0RvsKH54hlPJNX9ExPHkNpo2P6arncUwz9Cv6nQPq1M+C4/G25+XfLIJAAAAgGKETQAAAAAUI2wCAAAAoBhhEwAAAADFCJsAAAAAKEbYBAAAAEAxwiYAAAAAihE2AQAAAFCMsAkAAACAYoRNAAAAABQjbAIAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJgAAAACKETYBAAAAUExvR6/e6Ee0/en2tDld2ZnqapCqX+3mezhS5TZypG7SPayMkts4diJV3u2v5fYfEWtN7j20TZXuYb2ucz20k3QPg35uTP/H0afSPdST3LmoIncujh4/nqr/ahO5HtpJ/lz25+ZS9YuD3FiIiJjUuffRtm2qvtvL//xiLqa8x/ynTjffQz95XVYFzmWbnCOrAsehU+1sibC17yo3jjh3/uOJJ6LbmW4+7ffzi6x6tJ6qv+SSC9I9rK7lFqwnV/JrpLpOzsWd3LlYq0ep+oiIhx/536n6XvI9RER8+fEjqfrn7d2T7mH37qVU/eHDj6R7aCM3nv7nK69L1c+0i6n6iIg9Swup+rmT43QPx5aXU/VN9vkt8vPsyZVhqn51czVVHxGxlpznO4OZdA8b4+waa7r10Zma5Drv+ErueT4i4nkL0z27TNrtrxN8sgkAAACAYoRNAAAAABQjbAIAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJgAAAACKETYBAAAAUIywCQAAAIBihE0AAAAAFCNsAgAAAKAYYRMAAAAAxQibAAAAAChG2AQAAABAMcImAAAAAIrp7ejFVS96VX+qHY3bdqq6M62sb6bqnz55Mt3D06NcD3V/R4f8a2rrbqp+Y30jVV9tjlL1ERHjtknVdzq5YxARsWv3Yqq+28330O3lxkNbIC5uk9dm9jiUOI6dTpWsT7cQTXIjnSLjKXddTZpJqr5NnoeI/HHoFDiZVZV8H1W+hyZ5Luo63ULUU25kUmLnnBN128a0t4RjJ06k9784nE3Vn1xZS/eQvS83kZ/LV9dz7yM7DbbNem4DEbEwlzsOTz6dP5cP/a8vpup3zR1N97C5MU5uIXdfj4gYzObOxcOHc8fx/OHzUvUREQu7pnv+PO2CC/I9HPviE6n6qpdfIz15NDcmn//8fan6SZN/D5t17rljbfVUuoc6+T4mJebIxflU/ajJZyuro+nml3G9/TqfbAIAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJgAAAACKETYBAAAAUIywCQAAAIBihE0AAAAAFCNsAgAAAKAYYRMAAAAAxQibAAAAAChG2AQAAABAMcImAAAAAIoRNgEAAABQjLAJAAAAgGJ6O3nx6qnVGI/GU+3o5MnVqerO2v/Keq5+dSPdQ1Xl6heXFtM9zMzNpLeRUXXyGeVcb5Cq7w/yx6Db7eZ66O/o8vnaPfRy25g0TbqHtm2zW0juP7n7iOhmx2SVb2IymaTq67pO95A9l+NkD5PkWIiI6PZy12UveU1F5I/j7OxsuoeZ5PzSNrnxGBExMzPdPNspcI/g3Fjauzd6U94bFxd3pfc/mxz3T588le5hbm6Yqh+P8tfeqM5to9fPXYODmdwaLSJiNJnueeG0J5/On8uNOncc9i4spXt4/uXPS9WPx/m1wclTy6n6R790NFU/2N9P1UdEdNrccZgf5sd0dd6eVP3iXP4ZcGX5ZKr+0S8+mqp/4YtfkKqPiBi1uYfp0ST/PB/Jx6e11fz89IK9ufEwN5sf05vro6nqJu3271FWhAAAAAAUI2wCAAAAoBhhEwAAAADFCJsAAAAAKEbYBAAAAEAxwiYAAAAAihE2AQAAAFCMsAkAAACAYoRNAAAAABQjbAIAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJgAAAACKETYBAAAAUIywCQAAAIBiejt58bGnn47+oD/VjsajyVR1Z9rYGKXqR6NcfUREf3a69///6gfpHtbX11P1nW4uY+x0uqn6/2wiVd62VbqFelKn6ju9fFY7N5xJ1VedAnlx26bKJ02T7yGpqnLjoYr8eMpaW1tLb2Myyc2zvf6ObgnP0HbyxzE7prNjISKiTV4TUWI8JVuYnZ1LtzAzM9381ClwDjg3VtbWozvlGqFpxun9X3T+ean6wdww3cPaZm6tuGu4mO6h6uXm8qqbm0D6g/x9vapzc/naev65YTA3m6qf3zef7mHcya01616uPiJidil3XTS93LPPqZX8+uaKyy9N1ddPrKR7qFdzz18nVp5O93DFi65I1X/p8cOp+nGdvy6rncUPz7ByMj+emuTnbeaH+XvN/DCXCayu5o9Dd7gwVV0z3v685JNNAAAAABQjbAIAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJgAAAACKETYBAAAAUIywCQAAAIBihE0AAAAAFCNsAgAAAKAYYRMAAAAAxQibAAAAAChG2AQAAABAMcImAAAAAIoRNgEAAABQTG8nLx7Xo4iqnW5PbT7X6vX6qfqZmXQLMTM3l9tAle+h2tFZe6Zut5uqb6YcAmeatLkDMZlM0j10O7nj0B3k6iMiOv3cdTFIXhMREW2bO6HZc5HdfwlNfjhFp5M7l0tLS+kexuNxqn5zNErVT6a9P5yhqnJzQ4nxVNd1sj53HiIiYpLdRv44THttZ8ch587ccC56venubZM6N39ERGwmx06vn78v9/uDVH12jfVVuftJJ7k06PWb3AYK2Gzy80g15Vg+bbg7NxYiIk6dOpWqn8s+d0TE0aNPp+p7vYVU/Z65/DPgcGkxVT8/u57u4fz9u1P1T7XH0z0Mh7mL+7zz9qXqT508maqPiBgl19ydAs/Si7uXUvULi/nr8uSJ5VT9U089le6h7cxPVVfX2z+JPtkEAAAAQDHCJgAAAACKETYBAAAAUIywCQAAAIBihE0AAAAAFCNsAgAAAKAYYRMAAAAAxQibAAAAAChG2AQAAABAMcImAAAAAIoRNgEAAABQjLAJAAAAgGKETQAAAAAUI2wCAAAAoBhhEwAAAADFCJsAAAAAKKa3kxfv3bs3BoPBVDvqRH+qujNNJm2qflw3+R6qXA8bG+vpHqpulauvchlj0+SP42iS20a36aZ7yOp28z007SRVX2JMV5EbT+n9F9h90+Suy7rOnYeIiCY5P3V7+fFU13Wqfpytb3L1ERGd5HVVFRhQbZs8lwXmhk7kephMCozpKef6ejxO75tzY3ZuEL0p56JONd368Ezro81U/UyBtcHcTO59VJGfBwf95PtIrhMXd+/N7T8iNk6eSNWPeqN0D72Z3BppfbSR7qHbzY2nce6SiIiI0XrufnJk46lU/d6LL07VR0SMjzyZqp9LPr9FRMwu5K7L/bvPS/fw1LHHUvV7dy/mGujkn+dX6tygvvLCi9I9NG3uXK6t5dc5a6u5bezdvZTuYTzl7aqut3+P8ckmAAAAAIoRNgEAAABQjLAJAAAAgGKETQAAAAAUI2wCAAAAoBhhEwAAAADFCJsAAAAAKEbYBAAAAEAxwiYAAAAAihE2AQAAAFCMsAkAAACAYoRNAAAAABQjbAIAAACgGGETAAAAAMUImwAAAAAopreTFy8sLMTMzMxUO2om1VR1Z2lz2djmaJxu4eTaSqq+1++me+gmtzGZTHINJMsjIvqd3LmsmybdQ5M8Dk1b4EBUueNQtQWuq6bNbyO1+/z+m0luPLQFcvemzfUwWh+lexiPc3NcE8lz0cmPx+xoaArMDW2yi+HsbLqHQS83z3eq/Lno9Xa0RNgy7ubvc5wbg24net3p5sPhcJjef3Z90i2wQOl2c9fOZJJfa9Z17n7QTnkOTzt1Kn8Nr588maovcS5nZ6ebw04bjet0D+P13DbWTmymexj05lL1C3uXkg1M9+x4pvHaeqq+O8ivNQczg1R928+Nx4iIhcXcuZxJri2W9u5P1UdEtCefTtVXnfzcsHFqNVW/vlZgfkreM6sC67yY8hlsvIO50SebAAAAAChG2AQAAABAMcImAAAAAIoRNgEAAABQjLAJAAAAgGKETQAAAAAUI2wCAAAAoBhhEwAAAADFCJsAAAAAKEbYBAAAAEAxwiYAAAAAihE2AQAAAFCMsAkAAACAYoRNAAAAABQjbAIAAACgGGETAAAAAMX0dvLiKjpRTZlPVVU7Vd2ZRuPNVP3G5nq6h/F4lKrvdLvpHnqdXEbYTppU/aiuU/UREZv1JFVfdap0D1XyOHaqfA+dZA9Nnb+uslvIHoXcaPyqNnkuJk2+i7bKbaPTy4+nfref3kZGm38L0ba5ETmZ5K+JJruJNj+eOlXyZ0EFeqjH083Tk/E4vW/OjWF/Jvr96dYpvfTdIP8T0NnZ2XQPKysrqfpugXXeYGYmVT+3a3hO9x8RMZc8mesnltM9nH/eC1L1G5Fbq0ZELO3Kjcn+/kG6h+ztYBy55696kn9umJvflarvD/PHMTvFjQs8Nzxv/3yqftDs6NH/Gbq9/DpzZiZ3TbRtbjxGRAyHueM4V2I8Je8V6+v5XGPabYx3sD70ySYAAAAAihE2AQAAAFCMsAkAAACAYoRNAAAAABQjbAIAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJgAAAACKETYBAAAAUIywCQAAAIBihE0AAAAAFCNsAgAAAKAYYRMAAAAAxQibAAAAACimt5MXN00TTdNMtaPNzdFUdWcaj3PbGI020j2Mku9jNK7TPTTtdOfgtCqqVH23203VR0TMzsyk6ju9fA+TOncu2rZN9zDt9XRa1ckfh+x46HRymfWgwHjK2tjIzw11cjx1k8cxIn9tZsf05uZmqj4iYm1tPVVfVbnxHBExOzubqi9xLutR7lh2qnwPs7PTzdNV8h7FudOPNvpTzgOdSX59M+juaFn6DNn7WUT+npa9r0dEDPr9VH32ftQ0+XM5mzyOuxfm0z10ksNhdjBM99CMJqn64Xy+h3Hy2WVjfS1Vv1nnjkFExHCQmxv6g9xzR0TE6lruOMwuLKZ7WB/lrs315Fjot7m5KSKim3x26XRza7SIiElyibS2np/nl5ePp+qz83xExGAwmKquqra/TvDJJgAAAACKETYBAAAAUIywCQAAAIBihE0AAAAAFCNsAgAAAKAYYRMAAAAAxQibAAAAAChG2AQAAABAMcImAAAAAIoRNgEAAABQjLAJAAAAgGKETQAAAAAUI2wCAAAAoBhhEwAAAADFCJsAAAAAKEbYBAAAAEAxvZ28uB7X0elMl0+Nx6Op6s7af13nNtC26R56vR0dsmfqdNM9VMn6bjfXw7Rj4ExtJ/cuxtmxEPlzOZlM0j1UkRuT3W4/3UMnOSarKncu2wLXZds0qfrBYJDuIXtdbGxspHvIzpH9fm48ZeeWiPxxLHFdZo/jYHYm3cNwZpiqz94nIqa/tkvcIzg3Zvu9GPSnuzeWuPbaJreNEvfExcXFVH2TvB9F5O+ry8vHU/Vtk19j7Z6bS9XPD5Lr7Yhom9w9aX2zwDqvya1xmvFT6R4Wds2n6rPLtPxRjFgdbabq++P83LC+nuuh7qyne3jqxKlU/cqxk6n6paXnpeojIo6t5uan2bkCz6Ftbn45/vRauodTa7ltzCXn2Mw26nr7V7UVIQAAAADFCJsAAAAAKEbYBAAAAEAxwiYAAAAAihE2AQAAAFCMsAkAAACAYoRNAAAAABQjbAIAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJgAAAACKETYBAAAAUIywCQAAAIBiett5Udu2ERExGo2m3lGm9rS6rlP149E43cO4blP1dZurj4iokvXNpEnVdzr5jLJNbmJcT9I9VFXuSE6afA9tkxsPzSQ7GiI6ndz7yB7HtsA10Ta5MT0p0MMkOT/V4/z8lJUdTZNJ/prIzvNNiR6Sc1w9zs+R48iNyfzMMP21Pf7PsVzi2ubZcfpcjcfTXz+T5NoiIpKjPqIZ5+aPiIg2efE0yftRRH6dlV0jtQXWN6PEWIqIGCXXFhERnU5uRI2yi9WIqJLrvCo7ICNiM/n8M8peV5P8ddmJ3HjaHOV7yI7p5lugh+zckB4LBXrojgs8NySvq7rAc2j2nlmih2m3cbpuO+u8qt3Gq770pS/FJZdcMlUzAMB/P48//ng8//nPP9dtsA3WeQDATmxnnbetsKlpmvjyl78cCwsL6U8xAADfvtq2jVOnTsVFF11U5JOwfPNZ5wEA27GTdd62wiYAAAAA2A4/cgQAAACgGGETAAAAAMUImwAAAAAoRtgEAAAAQDHCJuAb+tmf/dl4zWte83Vfc+DAgXjPe97zrPQDAMC3rjvuuCOWlpa+7mtuvfXW+M7v/M6tr7ez3gSeO4RNQBH/+I//GL/4i794rtsAAPhvZzvhzreaW265JQ4dOnSu2wC+SXrnugHg28P+/fvPdQsAADxHzM/Px/z8/LluA/gm8ckmYMtHP/rRuPrqq2Nubi727dsXP/RDPxSrq6tb3//93//9uPDCC2Pfvn3xy7/8yzEej7e+919/ja6qqvjABz4QN954Y8zNzcXll18eH/3oR5/NtwMA8JzwqU99Km644YZYWlqKffv2xate9ar4whe+EBER9913X1RVFcvLy1uvf+ihh6Kqqnj00Ufjvvvui5/7uZ+LEydORFVVUVVV3HrrrRERcfz48fjpn/7p2LNnTwyHw7jxxhvj8OHDW9s5/Ymov/iLv4grr7wyhsNhvOENb4i1tbW4884748CBA7Fnz574tV/7tZhMJlt132i7p3384x+PK664ImZnZ+NHf/RH4/HHH9/63n/9Nbr/qmmauO222+Kyyy6Lubm5uPbaa60l4TlE2ARERMSRI0fizW9+c/z8z/98PPzww3HffffF6173umjbNiIi7r333vjCF74Q9957b9x5551xxx13xB133PF1t/n2t789Xv/618e//Mu/xE/+5E/Gm970pnj44YefhXcDAPDcsbq6Gr/+678eDz74YBw6dCg6nU689rWvjaZpvmHt9ddfH+95z3ticXExjhw5EkeOHIlbbrklIr76d5AefPDB+MQnPhF///d/H23bxite8YqzfmC4trYW733ve+Puu++OT33qU3HffffFa1/72rjnnnvinnvuiQ996ENx++23nxX0bHe773rXu+Kuu+6K+++/P5aXl+NNb3rTto/JbbfdFnfddVf84R/+Yfzbv/1b3HzzzfFTP/VT8dd//dfb3gZw7vg1OiAivho21XUdr3vd6+LSSy+NiIirr7566/t79uyJ97///dHtduMlL3lJvPKVr4xDhw7FW97ylv/vNm+66ab4hV/4hYiIeOc73xmf/vSn433ve1/8wR/8wTf3zQAAPIe8/vWvP+vrP/mTP4n9+/fHv//7v3/D2sFgELt3746qquKCCy7Y+vfDhw/HJz7xibj//vvj+uuvj4iID3/4w3HJJZfExz/+8bjpppsiImI8HscHPvCBeOELXxgREW94wxviQx/6UHzlK1+J+fn5uOqqq+IHf/AH49577403vvGNO9ru+9///vi+7/u+iIi488474+DBg/GZz3wmvvd7v/frvqfNzc347d/+7firv/qruO666yIi4vLLL4+//du/jdtvvz1+4Ad+4BseF+Dc8skmICIirr322nj5y18eV199ddx0003xwQ9+MI4fP771/e/4ju+Ibre79fWFF14YTz755Nfd5unFwZlf+2QTAMDZDh8+HG9+85vj8ssvj8XFxThw4EBERDz22GNTb/Phhx+OXq+3FfZEROzbty+uvPLKs9Zjw+FwK2iKiDj//PPjwIEDZ/09pfPPP39r3bfd7fZ6vfie7/mera9f8pKXxNLS0rbWgo888kisra3FD//wD2/9baf5+fm46667tn69EPjW5pNNQEREdLvd+PSnPx1/93d/F3/5l38Z73vf++I3f/M344EHHoiIiH6/f9brq6ra1ke7AQD4+n78x388Lr300vjgBz8YF110UTRNEy996UtjNBpthT6n/7RBRJz162pZX2uNd67XfSsrKxER8clPfjIuvvjis743MzPzrPUBTM8nm4AtVVXFy172snjHO94R//zP/xyDwSA+9rGPTb29f/iHf3jG1wcPHsy2CQDwbePYsWPxuc99Lt72trfFy1/+8jh48OBZny4//X/8PXLkyNa/PfTQQ2dtYzAYnPUHvCMiDh48GHVdb/3g8Mx9XXXVVVP3u93t1nUdDz744NbXn/vc52J5eXlba8GrrroqZmZm4rHHHosXvehFZ/13ySWXTN078OzxySYgIiIeeOCBOHToUPzIj/xInHfeefHAAw/E0aNH4+DBg/Gv//qvU23zz//8z+O7v/u744YbbogPf/jD8ZnPfCb++I//uHDnAADPXXv27Il9+/bFH/3RH8WFF14Yjz32WLz1rW/d+v7pgOXWW2+Nd73rXfH5z38+3v3ud5+1jQMHDsTKykocOnQorr322hgOh3HFFVfEq1/96njLW94St99+eywsLMRb3/rWuPjii+PVr3711P1ud7v9fj9+9Vd/Nd773vdGr9eLX/mVX4nv//7v/4Z/rykiYmFhIW655Za4+eabo2mauOGGG+LEiRNx//33x+LiYvzMz/zM1P0Dzw6fbAIiImJxcTH+5m/+Jl7xilfEi1/84njb294W7373u+PGG2+cepvveMc74u67745rrrkm7rrrrvjIRz6S+kkaAMC3m06nE3fffXf80z/9U7z0pS+Nm2++OX7v935v6/v9fj8+8pGPxGc/+9m45ppr4nd+53fit37rt87axvXXXx+/9Eu/FG984xtj//798bu/+7sREfGnf/qn8V3f9V3xqle9Kq677rpo2zbuueeeZ/ya3E5tZ7vD4TB+4zd+I37iJ34iXvayl8X8/Hz82Z/92bb38c53vjPe/va3x2233RYHDx6MH/uxH4tPfvKTcdlll6V6B54dVXvmL/8CFFJVVXzsYx+L17zmNee6FQAAAJ5FPtkEAAAAQDHCJgAAAACK8QfCgW8Kv6ELAADw35NPNgEAAABQjLAJAAAAgGKETQAAAAAUI2wCAAAAoBhhEwAAAADFCJsAAAAAKEbYBAAAAEAxwiYAAAAAivm/wZJE8NPnNKoAAAAASUVORK5CYII=\n"},"metadata":{}}],"source":["# Example usage\n","show_random_images(4)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tIk5GluBc9pl","executionInfo":{"status":"ok","timestamp":1715770046492,"user_tz":-60,"elapsed":27359,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"442eddf7-572a-4dc9-8f8e-595e9dc1aedc"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd '/content/drive/Othercomputers/My laptop/Documents/Hands-On Machine Learning with Scikit-Learn and TensorFlow'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2XGyi4vdVHt","executionInfo":{"status":"ok","timestamp":1715770047049,"user_tz":-60,"elapsed":560,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"502e1d03-c0e7-4d76-fba6-cf13f983964c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/My laptop/Documents/Hands-On Machine Learning with Scikit-Learn and TensorFlow\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApnHwx2odbXK","executionInfo":{"status":"ok","timestamp":1715770047049,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"5bf3e8da-2ed9-45a5-8a30-20d04581c6c3"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mchapter_10\u001b[0m/\n","chapter_10.ipynb\n","\u001b[01;34mchapter_11\u001b[0m/\n","chapter_11.ipynb\n","chapter_4.ipynb\n","chapter_5.ipynb\n","chapter_6.ipynb\n","chapter_7.ipynb\n","chapter_8.ipynb\n","chapter_9.ipynb\n","classification.ipynb\n","\u001b[01;34mdatasets\u001b[0m/\n","Hands-On_Machine_Learning_with_Scikit-Learn-Keras-and-TensorFlow-2nd-Edition-Aurelien-Geron.pdf\n","Housing.ipynb\n","\u001b[01;34mimages\u001b[0m/\n","requirements.txt\n"]}]},{"cell_type":"code","source":["# Function to create directory for storing models and training data\n","def get_chapter_directory(chapter_num):\n","    dir_name = f'chapter_{chapter_num}'\n","    if not os.path.exists(dir_name):\n","        os.makedirs(dir_name)\n","    return dir_name"],"metadata":{"id":"BLtMGGUvgtZG","executionInfo":{"status":"ok","timestamp":1715770051440,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"Czx0FPeMcbfU","executionInfo":{"status":"ok","timestamp":1715770051931,"user_tz":-60,"elapsed":1,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"outputs":[],"source":["# Create chapter directory\n","chapter_dir = get_chapter_directory(11)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"rAXoBcRzcbfV","executionInfo":{"status":"ok","timestamp":1715770060149,"user_tz":-60,"elapsed":425,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"outputs":[],"source":["# 3. Build the Model:\n","\n","checkpoint_path = os.path.join(chapter_dir, \"cifar10_dnn.weights.h5\")\n","tensorboard_log_dir = os.path.join(chapter_dir, \"logs\")\n","\n","# Create callbacks\n","checkpoint_cb = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n","tensorboard_cb = TensorBoard(log_dir=tensorboard_log_dir, histogram_freq=1)\n","early_stopping_cb = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n","\n","# Define the model\n","model = Sequential()\n","\n","# Flatten the input images\n","model.add(Flatten())\n","\n","# Add 20 hidden layers with 100 neurons each, He initialization, and ELU activation\n","for _ in range(20):\n","    model.add(Dense(100, kernel_initializer=HeNormal(), activation='elu'))\n","\n","\n","# Output layer with 10 neurons (one for each class), using softmax activation\n","model.add(Dense(10, activation='softmax'))"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"3YbusuoLcbfV","executionInfo":{"status":"ok","timestamp":1715770071051,"user_tz":-60,"elapsed":436,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"outputs":[],"source":["# 4. Compile the model\n","\n","# Compile the model with SGD optimizer\n","model.compile(optimizer=Nadam(learning_rate=0.001),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OB7R-RG3cbfV","executionInfo":{"status":"ok","timestamp":1715771075676,"user_tz":-60,"elapsed":990504,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"bafe8ea7-e047-4a05-8900-732e475225d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","1250/1250 [==============================] - ETA: 0s - loss: 2.0316 - accuracy: 0.2555\n","Epoch 1: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 29s 14ms/step - loss: 2.0316 - accuracy: 0.2555 - val_loss: 2.0198 - val_accuracy: 0.2773\n","Epoch 2/60\n","1245/1250 [============================>.] - ETA: 0s - loss: 1.8486 - accuracy: 0.3242\n","Epoch 2: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.8486 - accuracy: 0.3244 - val_loss: 1.8100 - val_accuracy: 0.3298\n","Epoch 3/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.7946 - accuracy: 0.3462\n","Epoch 3: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.7948 - accuracy: 0.3460 - val_loss: 1.8217 - val_accuracy: 0.3450\n","Epoch 4/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.7489 - accuracy: 0.3682\n","Epoch 4: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.7489 - accuracy: 0.3682 - val_loss: 1.7300 - val_accuracy: 0.3689\n","Epoch 5/60\n","1246/1250 [============================>.] - ETA: 0s - loss: 1.7053 - accuracy: 0.3874\n","Epoch 5: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.7054 - accuracy: 0.3875 - val_loss: 1.7376 - val_accuracy: 0.3856\n","Epoch 6/60\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.6820 - accuracy: 0.3958\n","Epoch 6: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6818 - accuracy: 0.3959 - val_loss: 1.6951 - val_accuracy: 0.4031\n","Epoch 7/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.6551 - accuracy: 0.4086\n","Epoch 7: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6554 - accuracy: 0.4085 - val_loss: 1.6600 - val_accuracy: 0.4061\n","Epoch 8/60\n","1246/1250 [============================>.] - ETA: 0s - loss: 1.6328 - accuracy: 0.4144\n","Epoch 8: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6323 - accuracy: 0.4146 - val_loss: 1.6491 - val_accuracy: 0.4184\n","Epoch 9/60\n","1245/1250 [============================>.] - ETA: 0s - loss: 1.6131 - accuracy: 0.4250\n","Epoch 9: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6133 - accuracy: 0.4250 - val_loss: 1.6527 - val_accuracy: 0.4135\n","Epoch 10/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.5938 - accuracy: 0.4300\n","Epoch 10: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.5938 - accuracy: 0.4300 - val_loss: 1.6019 - val_accuracy: 0.4334\n","Epoch 11/60\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.5729 - accuracy: 0.4390\n","Epoch 11: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 19s 15ms/step - loss: 1.5728 - accuracy: 0.4390 - val_loss: 1.6305 - val_accuracy: 0.4097\n","Epoch 12/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.5563 - accuracy: 0.4460\n","Epoch 12: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 17s 14ms/step - loss: 1.5563 - accuracy: 0.4460 - val_loss: 1.5793 - val_accuracy: 0.4466\n","Epoch 13/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.5336 - accuracy: 0.4524\n","Epoch 13: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 17s 13ms/step - loss: 1.5334 - accuracy: 0.4524 - val_loss: 1.6470 - val_accuracy: 0.4244\n","Epoch 14/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.5232 - accuracy: 0.4614\n","Epoch 14: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.5232 - accuracy: 0.4614 - val_loss: 1.5850 - val_accuracy: 0.4460\n","Epoch 15/60\n","1250/1250 [==============================] - ETA: 0s - loss: 17.0497 - accuracy: 0.4383\n","Epoch 15: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 12ms/step - loss: 17.0497 - accuracy: 0.4383 - val_loss: 1.9674 - val_accuracy: 0.2831\n","Epoch 16/60\n","1245/1250 [============================>.] - ETA: 0s - loss: 1.8131 - accuracy: 0.3376\n","Epoch 16: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.8129 - accuracy: 0.3378 - val_loss: 1.7706 - val_accuracy: 0.3569\n","Epoch 17/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.6831 - accuracy: 0.3884\n","Epoch 17: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6831 - accuracy: 0.3884 - val_loss: 1.7399 - val_accuracy: 0.3764\n","Epoch 18/60\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.6315 - accuracy: 0.4092\n","Epoch 18: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6314 - accuracy: 0.4092 - val_loss: 1.6707 - val_accuracy: 0.4049\n","Epoch 19/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.6985 - accuracy: 0.3821\n","Epoch 19: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 12ms/step - loss: 1.6985 - accuracy: 0.3821 - val_loss: 1.7151 - val_accuracy: 0.3837\n","Epoch 20/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.6222 - accuracy: 0.4092\n","Epoch 20: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6222 - accuracy: 0.4092 - val_loss: 1.6616 - val_accuracy: 0.3990\n","Epoch 21/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.5900 - accuracy: 0.4246\n","Epoch 21: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 12ms/step - loss: 1.5900 - accuracy: 0.4248 - val_loss: 1.6267 - val_accuracy: 0.4176\n","Epoch 22/60\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.6114 - accuracy: 0.4151\n","Epoch 22: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6115 - accuracy: 0.4151 - val_loss: 1.6042 - val_accuracy: 0.4202\n","Epoch 23/60\n","1246/1250 [============================>.] - ETA: 0s - loss: 1.5605 - accuracy: 0.4348\n","Epoch 23: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.5603 - accuracy: 0.4349 - val_loss: 1.6541 - val_accuracy: 0.4050\n","Epoch 24/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.5404 - accuracy: 0.4437\n","Epoch 24: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.5404 - accuracy: 0.4437 - val_loss: 1.6095 - val_accuracy: 0.4168\n","Epoch 25/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.5337 - accuracy: 0.4508\n","Epoch 25: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.5337 - accuracy: 0.4508 - val_loss: 1.5917 - val_accuracy: 0.4305\n","Epoch 26/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.5220 - accuracy: 0.4575\n","Epoch 26: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.5220 - accuracy: 0.4575 - val_loss: 1.5892 - val_accuracy: 0.4284\n","Epoch 27/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.5135 - accuracy: 0.4564\n","Epoch 27: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.5135 - accuracy: 0.4564 - val_loss: 1.5747 - val_accuracy: 0.4368\n","Epoch 28/60\n","1246/1250 [============================>.] - ETA: 0s - loss: 1.4970 - accuracy: 0.4626\n","Epoch 28: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4971 - accuracy: 0.4626 - val_loss: 1.6210 - val_accuracy: 0.4262\n","Epoch 29/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.4946 - accuracy: 0.4677\n","Epoch 29: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4946 - accuracy: 0.4677 - val_loss: 1.6015 - val_accuracy: 0.4441\n","Epoch 30/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.5992 - accuracy: 0.4267\n","Epoch 30: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 12ms/step - loss: 1.5988 - accuracy: 0.4269 - val_loss: 1.5913 - val_accuracy: 0.4423\n","Epoch 31/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.4965 - accuracy: 0.4632\n","Epoch 31: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.4964 - accuracy: 0.4632 - val_loss: 1.5735 - val_accuracy: 0.4400\n","Epoch 32/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.4731 - accuracy: 0.4727\n","Epoch 32: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.4731 - accuracy: 0.4725 - val_loss: 1.5884 - val_accuracy: 0.4328\n","Epoch 33/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.4577 - accuracy: 0.4796\n","Epoch 33: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4577 - accuracy: 0.4796 - val_loss: 1.5600 - val_accuracy: 0.4480\n","Epoch 34/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.4448 - accuracy: 0.4862\n","Epoch 34: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4446 - accuracy: 0.4863 - val_loss: 1.5632 - val_accuracy: 0.4595\n","Epoch 35/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.4323 - accuracy: 0.4879\n","Epoch 35: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4322 - accuracy: 0.4878 - val_loss: 1.5454 - val_accuracy: 0.4556\n","Epoch 36/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.4231 - accuracy: 0.4920\n","Epoch 36: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4232 - accuracy: 0.4920 - val_loss: 1.5569 - val_accuracy: 0.4565\n","Epoch 37/60\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.4075 - accuracy: 0.4984\n","Epoch 37: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4076 - accuracy: 0.4984 - val_loss: 1.5536 - val_accuracy: 0.4536\n","Epoch 38/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.3943 - accuracy: 0.5003\n","Epoch 38: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3942 - accuracy: 0.5003 - val_loss: 1.5370 - val_accuracy: 0.4654\n","Epoch 39/60\n","1246/1250 [============================>.] - ETA: 0s - loss: 1.3882 - accuracy: 0.5038\n","Epoch 39: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3884 - accuracy: 0.5038 - val_loss: 1.5472 - val_accuracy: 0.4640\n","Epoch 40/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.3715 - accuracy: 0.5125\n","Epoch 40: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3715 - accuracy: 0.5125 - val_loss: 1.5644 - val_accuracy: 0.4540\n","Epoch 41/60\n","1245/1250 [============================>.] - ETA: 0s - loss: 1.3592 - accuracy: 0.5143\n","Epoch 41: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3590 - accuracy: 0.5142 - val_loss: 1.5540 - val_accuracy: 0.4525\n","Epoch 42/60\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.3725 - accuracy: 0.5108\n","Epoch 42: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3723 - accuracy: 0.5109 - val_loss: 1.5217 - val_accuracy: 0.4806\n","Epoch 43/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.3438 - accuracy: 0.5200\n","Epoch 43: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3436 - accuracy: 0.5200 - val_loss: 1.5209 - val_accuracy: 0.4745\n","Epoch 44/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.3353 - accuracy: 0.5272\n","Epoch 44: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3353 - accuracy: 0.5272 - val_loss: 1.5301 - val_accuracy: 0.4801\n","Epoch 45/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.3260 - accuracy: 0.5282\n","Epoch 45: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3256 - accuracy: 0.5283 - val_loss: 1.5157 - val_accuracy: 0.4849\n","Epoch 46/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.4558 - accuracy: 0.4835\n","Epoch 46: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4559 - accuracy: 0.4835 - val_loss: 1.8012 - val_accuracy: 0.3657\n","Epoch 47/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.5068 - accuracy: 0.4610\n","Epoch 47: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.5068 - accuracy: 0.4609 - val_loss: 1.5644 - val_accuracy: 0.4439\n","Epoch 48/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.3473 - accuracy: 0.5244\n","Epoch 48: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3473 - accuracy: 0.5244 - val_loss: 1.5054 - val_accuracy: 0.4738\n","Epoch 49/60\n","1246/1250 [============================>.] - ETA: 0s - loss: 1.3060 - accuracy: 0.5348\n","Epoch 49: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3063 - accuracy: 0.5346 - val_loss: 1.5222 - val_accuracy: 0.4788\n","Epoch 50/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.2937 - accuracy: 0.5405\n","Epoch 50: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.2937 - accuracy: 0.5405 - val_loss: 1.5251 - val_accuracy: 0.4690\n","Epoch 51/60\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.2947 - accuracy: 0.5431\n","Epoch 51: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.2948 - accuracy: 0.5432 - val_loss: 1.5502 - val_accuracy: 0.4574\n","Epoch 52/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.2794 - accuracy: 0.5462\n","Epoch 52: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 12ms/step - loss: 1.2795 - accuracy: 0.5461 - val_loss: 1.5549 - val_accuracy: 0.4727\n","Epoch 53/60\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.3040 - accuracy: 0.5356\n","Epoch 53: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3038 - accuracy: 0.5356 - val_loss: 1.5349 - val_accuracy: 0.4762\n","Epoch 54/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.2747 - accuracy: 0.5475\n","Epoch 54: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.2745 - accuracy: 0.5476 - val_loss: 1.5183 - val_accuracy: 0.4874\n","Epoch 55/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.2491 - accuracy: 0.5578\n","Epoch 55: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.2490 - accuracy: 0.5577 - val_loss: 1.5491 - val_accuracy: 0.4787\n","Epoch 56/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.4344 - accuracy: 0.5250\n","Epoch 56: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4353 - accuracy: 0.5245 - val_loss: 1.9112 - val_accuracy: 0.3131\n","Epoch 57/60\n","1247/1250 [============================>.] - ETA: 0s - loss: 1.6113 - accuracy: 0.4228\n","Epoch 57: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.6113 - accuracy: 0.4228 - val_loss: 1.6488 - val_accuracy: 0.4141\n","Epoch 58/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.4577 - accuracy: 0.4795\n","Epoch 58: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.4577 - accuracy: 0.4795 - val_loss: 1.5647 - val_accuracy: 0.4500\n","Epoch 59/60\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.3746 - accuracy: 0.5065\n","Epoch 59: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3747 - accuracy: 0.5065 - val_loss: 1.5401 - val_accuracy: 0.4653\n","Epoch 60/60\n","1250/1250 [==============================] - ETA: 0s - loss: 1.3234 - accuracy: 0.5285\n","Epoch 60: saving model to chapter_11/cifar10_dnn.weights.h5\n","1250/1250 [==============================] - 15s 12ms/step - loss: 1.3234 - accuracy: 0.5285 - val_loss: 1.5299 - val_accuracy: 0.4760\n"]}],"source":["# Train the model with callbacks\n","history = model.fit(x_train, y_train,\n","                    epochs=60,\n","                    batch_size=32,\n","                    validation_split=.2,\n","                    callbacks=[checkpoint_cb, tensorboard_cb, early_stopping_cb])"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V5WDzdH5cbfW","executionInfo":{"status":"ok","timestamp":1715771356297,"user_tz":-60,"elapsed":1931,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"f7e88b76-aea7-4421-92a2-8540fb3c79b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 1.5106 - accuracy: 0.4781\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.510593056678772, 0.4781000018119812]"]},"metadata":{},"execution_count":32}],"source":["model.evaluate(x_test, y_test)"]},{"cell_type":"code","source":["from tensorflow.keras.layers import BatchNormalization"],"metadata":{"id":"nOkQF95dg7rq","executionInfo":{"status":"ok","timestamp":1715771364813,"user_tz":-60,"elapsed":1,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["checkpoint_path = os.path.join(chapter_dir, \"cifar10_dnn_bn.weights.h5\")\n","tensorboard_log_dir = os.path.join(chapter_dir, \"logs_bn\")\n","\n","# Create callbacks\n","checkpoint_cb = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n","tensorboard_cb = TensorBoard(log_dir=tensorboard_log_dir, histogram_freq=1)\n"],"metadata":{"id":"z9NrOHlRg_qM","executionInfo":{"status":"ok","timestamp":1715771366439,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Build the model with Batch Normalization\n","model_bn = Sequential()\n","model_bn.add(Flatten())\n","for _ in range(20):\n","    model_bn.add(Dense(100, kernel_initializer=HeNormal()))\n","    model_bn.add(BatchNormalization())\n","    model_bn.add(ELU())\n","model_bn.add(Dense(10, activation='softmax'))\n","# Compile the model with Nadam optimizer\n","model_bn.compile(optimizer=Nadam(learning_rate=0.001),  # Adjust the learning rate as necessary\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])"],"metadata":{"id":"_5NANh11hYdl","executionInfo":{"status":"ok","timestamp":1715771374604,"user_tz":-60,"elapsed":426,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Train the model with callbacks\n","history_bn = model_bn.fit(x_train, y_train,\n","                          epochs=100,\n","                          batch_size=32,\n","                          validation_split=.2,\n","                          callbacks=[checkpoint_cb, tensorboard_cb, early_stopping_cb])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EVYcOJsDhi2u","executionInfo":{"status":"ok","timestamp":1715772689626,"user_tz":-60,"elapsed":1311065,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"9bd3945e-894f-48d9-aa7e-364b0b9abaf0"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.8535 - accuracy: 0.3363\n","Epoch 1: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 55s 26ms/step - loss: 1.8533 - accuracy: 0.3363 - val_loss: 1.7759 - val_accuracy: 0.3560\n","Epoch 2/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.6987 - accuracy: 0.3932\n","Epoch 2: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.6987 - accuracy: 0.3932 - val_loss: 1.9657 - val_accuracy: 0.3302\n","Epoch 3/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.6357 - accuracy: 0.4169\n","Epoch 3: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.6357 - accuracy: 0.4169 - val_loss: 1.7546 - val_accuracy: 0.3765\n","Epoch 4/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.5892 - accuracy: 0.4322\n","Epoch 4: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.5893 - accuracy: 0.4322 - val_loss: 1.6384 - val_accuracy: 0.4128\n","Epoch 5/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.5440 - accuracy: 0.4506\n","Epoch 5: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.5440 - accuracy: 0.4506 - val_loss: 1.5626 - val_accuracy: 0.4408\n","Epoch 6/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.5046 - accuracy: 0.4654\n","Epoch 6: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 26ms/step - loss: 1.5046 - accuracy: 0.4654 - val_loss: 1.6120 - val_accuracy: 0.4283\n","Epoch 7/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.4700 - accuracy: 0.4782\n","Epoch 7: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.4700 - accuracy: 0.4782 - val_loss: 1.5476 - val_accuracy: 0.4511\n","Epoch 8/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.4339 - accuracy: 0.4909\n","Epoch 8: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 24ms/step - loss: 1.4339 - accuracy: 0.4909 - val_loss: 1.6188 - val_accuracy: 0.4374\n","Epoch 9/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.4038 - accuracy: 0.5039\n","Epoch 9: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.4037 - accuracy: 0.5039 - val_loss: 1.6186 - val_accuracy: 0.4240\n","Epoch 10/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.3833 - accuracy: 0.5094\n","Epoch 10: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 26ms/step - loss: 1.3833 - accuracy: 0.5094 - val_loss: 1.5776 - val_accuracy: 0.4497\n","Epoch 11/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.3524 - accuracy: 0.5240\n","Epoch 11: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.3524 - accuracy: 0.5240 - val_loss: 1.4858 - val_accuracy: 0.4856\n","Epoch 12/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.3324 - accuracy: 0.5290\n","Epoch 12: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.3323 - accuracy: 0.5290 - val_loss: 1.4560 - val_accuracy: 0.4926\n","Epoch 13/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.3087 - accuracy: 0.5384\n","Epoch 13: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.3090 - accuracy: 0.5384 - val_loss: 1.5469 - val_accuracy: 0.4577\n","Epoch 14/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.2869 - accuracy: 0.5480\n","Epoch 14: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 26ms/step - loss: 1.2869 - accuracy: 0.5480 - val_loss: 1.5730 - val_accuracy: 0.4572\n","Epoch 15/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.2656 - accuracy: 0.5556\n","Epoch 15: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.2655 - accuracy: 0.5555 - val_loss: 1.4436 - val_accuracy: 0.4936\n","Epoch 16/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.2480 - accuracy: 0.5628\n","Epoch 16: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 26ms/step - loss: 1.2480 - accuracy: 0.5628 - val_loss: 1.4934 - val_accuracy: 0.4751\n","Epoch 17/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.2268 - accuracy: 0.5678\n","Epoch 17: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.2268 - accuracy: 0.5678 - val_loss: 1.5163 - val_accuracy: 0.4777\n","Epoch 18/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.2133 - accuracy: 0.5721\n","Epoch 18: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 25ms/step - loss: 1.2133 - accuracy: 0.5721 - val_loss: 1.5588 - val_accuracy: 0.4814\n","Epoch 19/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.1961 - accuracy: 0.5822\n","Epoch 19: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.1960 - accuracy: 0.5822 - val_loss: 1.7254 - val_accuracy: 0.4396\n","Epoch 20/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.1786 - accuracy: 0.5847\n","Epoch 20: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.1786 - accuracy: 0.5847 - val_loss: 1.4951 - val_accuracy: 0.4863\n","Epoch 21/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.1575 - accuracy: 0.5915\n","Epoch 21: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.1575 - accuracy: 0.5915 - val_loss: 1.6202 - val_accuracy: 0.4565\n","Epoch 22/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.1403 - accuracy: 0.5988\n","Epoch 22: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 25ms/step - loss: 1.1403 - accuracy: 0.5988 - val_loss: 1.5393 - val_accuracy: 0.4754\n","Epoch 23/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.1233 - accuracy: 0.6070\n","Epoch 23: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 24ms/step - loss: 1.1234 - accuracy: 0.6069 - val_loss: 1.5305 - val_accuracy: 0.4849\n","Epoch 24/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.1157 - accuracy: 0.6089\n","Epoch 24: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.1157 - accuracy: 0.6089 - val_loss: 1.4855 - val_accuracy: 0.5013\n","Epoch 25/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.0984 - accuracy: 0.6153\n","Epoch 25: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.0986 - accuracy: 0.6151 - val_loss: 1.6519 - val_accuracy: 0.4587\n","Epoch 26/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.0917 - accuracy: 0.6181\n","Epoch 26: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 33s 26ms/step - loss: 1.0916 - accuracy: 0.6180 - val_loss: 1.4333 - val_accuracy: 0.5176\n","Epoch 27/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.0709 - accuracy: 0.6238\n","Epoch 27: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 44s 35ms/step - loss: 1.0709 - accuracy: 0.6238 - val_loss: 1.6765 - val_accuracy: 0.4511\n","Epoch 28/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.0552 - accuracy: 0.6287\n","Epoch 28: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.0554 - accuracy: 0.6285 - val_loss: 1.6543 - val_accuracy: 0.4742\n","Epoch 29/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.0429 - accuracy: 0.6345\n","Epoch 29: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.0429 - accuracy: 0.6345 - val_loss: 1.5892 - val_accuracy: 0.4889\n","Epoch 30/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 1.0302 - accuracy: 0.6409\n","Epoch 30: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 1.0300 - accuracy: 0.6409 - val_loss: 1.5445 - val_accuracy: 0.4905\n","Epoch 31/100\n","1250/1250 [==============================] - ETA: 0s - loss: 1.0247 - accuracy: 0.6412\n","Epoch 31: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.0247 - accuracy: 0.6412 - val_loss: 1.6292 - val_accuracy: 0.4711\n","Epoch 32/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 1.0016 - accuracy: 0.6477\n","Epoch 32: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 1.0015 - accuracy: 0.6478 - val_loss: 1.6086 - val_accuracy: 0.4793\n","Epoch 33/100\n","1250/1250 [==============================] - ETA: 0s - loss: 0.9920 - accuracy: 0.6498\n","Epoch 33: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 0.9920 - accuracy: 0.6498 - val_loss: 1.6749 - val_accuracy: 0.4596\n","Epoch 34/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 0.9805 - accuracy: 0.6558\n","Epoch 34: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 0.9805 - accuracy: 0.6559 - val_loss: 1.6159 - val_accuracy: 0.4815\n","Epoch 35/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 0.9688 - accuracy: 0.6612\n","Epoch 35: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 0.9683 - accuracy: 0.6614 - val_loss: 1.6874 - val_accuracy: 0.4588\n","Epoch 36/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 0.9641 - accuracy: 0.6612\n","Epoch 36: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 25ms/step - loss: 0.9641 - accuracy: 0.6612 - val_loss: 1.4998 - val_accuracy: 0.5037\n","Epoch 37/100\n","1250/1250 [==============================] - ETA: 0s - loss: 0.9489 - accuracy: 0.6685\n","Epoch 37: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 25ms/step - loss: 0.9489 - accuracy: 0.6685 - val_loss: 1.6337 - val_accuracy: 0.4772\n","Epoch 38/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 0.9354 - accuracy: 0.6712\n","Epoch 38: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 30s 24ms/step - loss: 0.9354 - accuracy: 0.6712 - val_loss: 1.5047 - val_accuracy: 0.5066\n","Epoch 39/100\n","1249/1250 [============================>.] - ETA: 0s - loss: 0.9249 - accuracy: 0.6764\n","Epoch 39: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 0.9248 - accuracy: 0.6765 - val_loss: 1.5238 - val_accuracy: 0.5127\n","Epoch 40/100\n","1250/1250 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.6761\n","Epoch 40: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 32s 25ms/step - loss: 0.9215 - accuracy: 0.6761 - val_loss: 1.9132 - val_accuracy: 0.4558\n","Epoch 41/100\n","1248/1250 [============================>.] - ETA: 0s - loss: 0.9034 - accuracy: 0.6854\n","Epoch 41: saving model to chapter_11/cifar10_dnn_bn.weights.h5\n","1250/1250 [==============================] - 31s 25ms/step - loss: 0.9040 - accuracy: 0.6851 - val_loss: 1.7114 - val_accuracy: 0.4547\n"]}]},{"cell_type":"code","source":["model_bn.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wszuzqGg_i8x","executionInfo":{"status":"ok","timestamp":1715772915004,"user_tz":-60,"elapsed":12642,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"a7fa164f-0732-4fae-957d-b4bd9d3b08ca"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 4ms/step - loss: 1.4262 - accuracy: 0.5094\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.4262179136276245, 0.5094000101089478]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","# Standardize the input features\n","scaler = StandardScaler()\n","x_train_scaled = scaler.fit_transform(x_train.reshape(-1, 32 * 32 * 3)).reshape(-1, 32, 32, 3)\n","x_test_scaled = scaler.transform(x_test.reshape(-1, 32 * 32 * 3)).reshape(-1, 32, 32, 3)\n","\n","# Scale the data to the range [-1, 1]\n","scaler_minmax = MinMaxScaler(feature_range=(-1, 1))\n","x_train_scaled = scaler_minmax.fit_transform(x_train_scaled.reshape(-1, 32 * 32 * 3)).reshape(-1, 32, 32, 3)\n","x_test_scaled = scaler_minmax.transform(x_test_scaled.reshape(-1, 32 * 32 * 3)).reshape(-1, 32, 32, 3)"],"metadata":{"id":"X2NkYKgchtxe","executionInfo":{"status":"ok","timestamp":1715772934704,"user_tz":-60,"elapsed":5304,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["np.min(x_train_scaled), np.max(x_train_scaled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJvXvBQi9Bal","executionInfo":{"status":"ok","timestamp":1715772957121,"user_tz":-60,"elapsed":517,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"28616762-cc2e-46f4-bf3c-8637454ced80"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-1.0, 1.0000000000000004)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["# Build the model with SELU activation and LeCun Normal initialization\n","model_selu = Sequential()\n","model_selu.add(Flatten())\n","for _ in range(20):\n","    model_selu.add(Dense(100, kernel_initializer=\"lecun_normal\", activation='selu'))\n","model_selu.add(Dense(10, activation='softmax'))"],"metadata":{"id":"PnkH4VmNntHA","executionInfo":{"status":"ok","timestamp":1715772983278,"user_tz":-60,"elapsed":1,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["checkpoint_path = os.path.join(chapter_dir, \"cifar10_lecuninit.weights.h5\")\n","tensorboard_log_dir = os.path.join(chapter_dir, \"logs_lecuninit\")\n","\n","# Create callbacks\n","checkpoint_cb = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n","tensorboard_cb = TensorBoard(log_dir=tensorboard_log_dir, histogram_freq=1)"],"metadata":{"id":"yHlyl5AutgmM","executionInfo":{"status":"ok","timestamp":1715772987564,"user_tz":-60,"elapsed":428,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# Compile the model with Nadam optimizer\n","model_selu.compile(optimizer=Nadam(learning_rate=0.001),  # Adjust the learning rate as necessary\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n"],"metadata":{"id":"ff8sCyH1n6BL","executionInfo":{"status":"ok","timestamp":1715772989349,"user_tz":-60,"elapsed":2,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# Train the model with callbacks\n","history_selu = model_selu.fit(x_train_scaled, y_train,\n","                              epochs=100,\n","                              batch_size=32,\n","                              validation_split=.1,\n","                              callbacks=[checkpoint_cb, tensorboard_cb, early_stopping_cb])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj2lgbQ8tcHw","executionInfo":{"status":"ok","timestamp":1715777253208,"user_tz":-60,"elapsed":4257509,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"3ec28c4b-c083-49ce-dc12-f9ef3b15e004"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9687 - accuracy: 0.2857\n","Epoch 1: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 27s 13ms/step - loss: 1.9684 - accuracy: 0.2858 - val_loss: 1.8778 - val_accuracy: 0.3280\n","Epoch 2/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.7780 - accuracy: 0.3622\n","Epoch 2: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7781 - accuracy: 0.3622 - val_loss: 1.7880 - val_accuracy: 0.3594\n","Epoch 3/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.6875 - accuracy: 0.4006\n","Epoch 3: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6875 - accuracy: 0.4006 - val_loss: 1.7145 - val_accuracy: 0.4020\n","Epoch 4/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.6256 - accuracy: 0.4247\n","Epoch 4: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.6259 - accuracy: 0.4247 - val_loss: 1.6671 - val_accuracy: 0.4214\n","Epoch 5/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.5746 - accuracy: 0.4433\n","Epoch 5: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5746 - accuracy: 0.4433 - val_loss: 1.6085 - val_accuracy: 0.4410\n","Epoch 6/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 0.4635\n","Epoch 6: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.5303 - accuracy: 0.4635 - val_loss: 1.5738 - val_accuracy: 0.4586\n","Epoch 7/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.5024 - accuracy: 0.4729\n","Epoch 7: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.5024 - accuracy: 0.4730 - val_loss: 1.5861 - val_accuracy: 0.4476\n","Epoch 8/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.4676 - accuracy: 0.4860\n","Epoch 8: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.4678 - accuracy: 0.4859 - val_loss: 1.5473 - val_accuracy: 0.4686\n","Epoch 9/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.4389 - accuracy: 0.4953\n","Epoch 9: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4389 - accuracy: 0.4954 - val_loss: 1.5747 - val_accuracy: 0.4570\n","Epoch 10/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.4064 - accuracy: 0.5071\n","Epoch 10: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4064 - accuracy: 0.5071 - val_loss: 1.5254 - val_accuracy: 0.4732\n","Epoch 11/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.5281 - accuracy: 0.4691\n","Epoch 11: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.5283 - accuracy: 0.4690 - val_loss: 1.7928 - val_accuracy: 0.3352\n","Epoch 12/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.5932 - accuracy: 0.4235\n","Epoch 12: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.5931 - accuracy: 0.4236 - val_loss: 1.5883 - val_accuracy: 0.4438\n","Epoch 13/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.4560 - accuracy: 0.4845\n","Epoch 13: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.4559 - accuracy: 0.4846 - val_loss: 1.5627 - val_accuracy: 0.4522\n","Epoch 14/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.4008 - accuracy: 0.5043\n","Epoch 14: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.4005 - accuracy: 0.5044 - val_loss: 1.5106 - val_accuracy: 0.4716\n","Epoch 15/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.3686 - accuracy: 0.5176\n","Epoch 15: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3681 - accuracy: 0.5178 - val_loss: 1.5102 - val_accuracy: 0.4816\n","Epoch 16/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.3363 - accuracy: 0.5332\n","Epoch 16: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.3363 - accuracy: 0.5332 - val_loss: 1.5200 - val_accuracy: 0.4772\n","Epoch 17/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.3166 - accuracy: 0.5389\n","Epoch 17: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.3166 - accuracy: 0.5388 - val_loss: 1.5033 - val_accuracy: 0.4922\n","Epoch 18/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.3222 - accuracy: 0.5492\n","Epoch 18: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.3222 - accuracy: 0.5492 - val_loss: 1.9794 - val_accuracy: 0.4148\n","Epoch 19/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.4665 - accuracy: 0.4855\n","Epoch 19: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.4661 - accuracy: 0.4856 - val_loss: 1.5482 - val_accuracy: 0.4666\n","Epoch 20/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.2908 - accuracy: 0.5516\n","Epoch 20: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.2909 - accuracy: 0.5515 - val_loss: 1.4887 - val_accuracy: 0.4924\n","Epoch 21/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.2505 - accuracy: 0.5645\n","Epoch 21: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.2506 - accuracy: 0.5644 - val_loss: 1.5163 - val_accuracy: 0.4900\n","Epoch 22/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.2338 - accuracy: 0.5710\n","Epoch 22: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2335 - accuracy: 0.5710 - val_loss: 1.4766 - val_accuracy: 0.4932\n","Epoch 23/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.2251 - accuracy: 0.5743\n","Epoch 23: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2251 - accuracy: 0.5743 - val_loss: 1.4852 - val_accuracy: 0.5050\n","Epoch 24/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.2140 - accuracy: 0.5814\n","Epoch 24: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.2143 - accuracy: 0.5813 - val_loss: 1.5429 - val_accuracy: 0.4968\n","Epoch 25/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.2056 - accuracy: 0.5812\n","Epoch 25: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.2056 - accuracy: 0.5812 - val_loss: 1.5063 - val_accuracy: 0.4914\n","Epoch 26/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.1899 - accuracy: 0.5884\n","Epoch 26: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1906 - accuracy: 0.5883 - val_loss: 1.5080 - val_accuracy: 0.4982\n","Epoch 27/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.1885 - accuracy: 0.5885\n","Epoch 27: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1885 - accuracy: 0.5885 - val_loss: 1.5205 - val_accuracy: 0.5032\n","Epoch 28/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.1610 - accuracy: 0.5988\n","Epoch 28: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1612 - accuracy: 0.5988 - val_loss: 1.6107 - val_accuracy: 0.4798\n","Epoch 29/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.1609 - accuracy: 0.5984\n","Epoch 29: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1615 - accuracy: 0.5982 - val_loss: 1.5578 - val_accuracy: 0.5032\n","Epoch 30/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.1627 - accuracy: 0.5989\n","Epoch 30: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1627 - accuracy: 0.5989 - val_loss: 1.5951 - val_accuracy: 0.4782\n","Epoch 31/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.1395 - accuracy: 0.6070\n","Epoch 31: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.1395 - accuracy: 0.6070 - val_loss: 1.5346 - val_accuracy: 0.5014\n","Epoch 32/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.1416 - accuracy: 0.6061\n","Epoch 32: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1415 - accuracy: 0.6062 - val_loss: 1.6076 - val_accuracy: 0.5014\n","Epoch 33/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 38.1332 - accuracy: 0.5945\n","Epoch 33: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 38.1265 - accuracy: 0.5946 - val_loss: 1.5464 - val_accuracy: 0.4884\n","Epoch 34/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.1190 - accuracy: 0.6111\n","Epoch 34: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1190 - accuracy: 0.6111 - val_loss: 1.5444 - val_accuracy: 0.4942\n","Epoch 35/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.0963 - accuracy: 0.6210\n","Epoch 35: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.0963 - accuracy: 0.6210 - val_loss: 1.5558 - val_accuracy: 0.5048\n","Epoch 36/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.0761 - accuracy: 0.6273\n","Epoch 36: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.0763 - accuracy: 0.6273 - val_loss: 1.5461 - val_accuracy: 0.5062\n","Epoch 37/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.0414 - accuracy: 0.6406\n","Epoch 37: saving model to chapter_11/cifar10_lecuninit.weights.h5\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.0413 - accuracy: 0.6405 - val_loss: 1.6366 - val_accuracy: 0.4970\n"]}]},{"cell_type":"code","source":["model_selu.evaluate(x_test_scaled, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sm2guzbnCdyn","executionInfo":{"status":"ok","timestamp":1715777527092,"user_tz":-60,"elapsed":2892,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"cf77df08-6cdb-4b21-be99-80e355f77f94"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 2s 7ms/step - loss: 1.4715 - accuracy: 0.4884\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.4714914560317993, 0.48840001225471497]"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["# Build the model with SELU activation, LeCun Normal initialization, and Alpha Dropout\n","model_alpha_dropout = Sequential()\n","model_alpha_dropout.add(Flatten())\n","for _ in range(20):\n","    model_alpha_dropout.add(Dense(100, kernel_initializer=\"lecun_normal\", activation='selu'))\n","    model_alpha_dropout.add(AlphaDropout(0.1))  # Adjust dropout rate as necessary\n","model_alpha_dropout.add(Dense(10, activation='softmax'))"],"metadata":{"id":"UlCbHMb9twAl","executionInfo":{"status":"ok","timestamp":1715777593033,"user_tz":-60,"elapsed":444,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["checkpoint_path = os.path.join(chapter_dir, \"cifar10_mc_alphadrop.weights.h5\")\n","tensorboard_log_dir = os.path.join(chapter_dir, \"logs_mc_alphadrop\")\n","\n","# Create callbacks\n","checkpoint_cb = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n","tensorboard_cb = TensorBoard(log_dir=tensorboard_log_dir, histogram_freq=1)"],"metadata":{"id":"EGmMMch8zCoi","executionInfo":{"status":"ok","timestamp":1715777597109,"user_tz":-60,"elapsed":2,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Compile the model with Nadam optimizer\n","model_alpha_dropout.compile(optimizer=Nadam(learning_rate=0.001),  # Adjust the learning rate as necessary\n","                            loss='categorical_crossentropy',\n","                            metrics=['accuracy'])"],"metadata":{"id":"-e1YDpZRzanD","executionInfo":{"status":"ok","timestamp":1715777601831,"user_tz":-60,"elapsed":533,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["# Train the model with callbacks\n","history_alpha_dropout = model_alpha_dropout.fit(x_train_scaled, y_train,\n","                                                epochs=100,\n","                                                batch_size=32,\n","                                                validation_split=.1,\n","                                                callbacks=[checkpoint_cb, tensorboard_cb, early_stopping_cb])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9kejBs1czgQR","executionInfo":{"status":"ok","timestamp":1715778210346,"user_tz":-60,"elapsed":594493,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"cd5f5bd2-aa10-4ca1-a5f8-dded2e0cab1c"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1407/1407 [==============================] - ETA: 0s - loss: 2.1427 - accuracy: 0.1980\n","Epoch 1: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 30s 14ms/step - loss: 2.1427 - accuracy: 0.1980 - val_loss: 5.4438 - val_accuracy: 0.2392\n","Epoch 2/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9830 - accuracy: 0.2293\n","Epoch 2: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.9826 - accuracy: 0.2293 - val_loss: 4.7514 - val_accuracy: 0.2236\n","Epoch 3/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.9497 - accuracy: 0.2475\n","Epoch 3: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9498 - accuracy: 0.2475 - val_loss: 5.5641 - val_accuracy: 0.2420\n","Epoch 4/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9276 - accuracy: 0.2606\n","Epoch 4: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9276 - accuracy: 0.2606 - val_loss: 6.0744 - val_accuracy: 0.2650\n","Epoch 5/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9233 - accuracy: 0.2650\n","Epoch 5: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9235 - accuracy: 0.2650 - val_loss: 4.2357 - val_accuracy: 0.2652\n","Epoch 6/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9238 - accuracy: 0.2658\n","Epoch 6: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9238 - accuracy: 0.2658 - val_loss: 7.0857 - val_accuracy: 0.2158\n","Epoch 7/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9252 - accuracy: 0.2695\n","Epoch 7: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9250 - accuracy: 0.2696 - val_loss: 4.8968 - val_accuracy: 0.2680\n","Epoch 8/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9229 - accuracy: 0.2687\n","Epoch 8: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9229 - accuracy: 0.2686 - val_loss: 5.5143 - val_accuracy: 0.2758\n","Epoch 9/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.8952 - accuracy: 0.2873\n","Epoch 9: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.8955 - accuracy: 0.2872 - val_loss: 8.8104 - val_accuracy: 0.2802\n","Epoch 10/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.8914 - accuracy: 0.2900\n","Epoch 10: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.8913 - accuracy: 0.2900 - val_loss: 5.5568 - val_accuracy: 0.2756\n","Epoch 11/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9619 - accuracy: 0.2743\n","Epoch 11: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9620 - accuracy: 0.2742 - val_loss: 6.8972 - val_accuracy: 0.2284\n","Epoch 12/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9525 - accuracy: 0.2642\n","Epoch 12: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.9526 - accuracy: 0.2642 - val_loss: 5.4324 - val_accuracy: 0.2580\n","Epoch 13/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.9057 - accuracy: 0.2855\n","Epoch 13: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9057 - accuracy: 0.2855 - val_loss: 5.4329 - val_accuracy: 0.2592\n","Epoch 14/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9260 - accuracy: 0.2657\n","Epoch 14: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9258 - accuracy: 0.2658 - val_loss: 5.4458 - val_accuracy: 0.2646\n","Epoch 15/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9056 - accuracy: 0.2700\n","Epoch 15: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9055 - accuracy: 0.2700 - val_loss: 3.8402 - val_accuracy: 0.2578\n","Epoch 16/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9115 - accuracy: 0.2651\n","Epoch 16: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 21s 15ms/step - loss: 1.9112 - accuracy: 0.2651 - val_loss: 5.6700 - val_accuracy: 0.2430\n","Epoch 17/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9091 - accuracy: 0.2686\n","Epoch 17: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9091 - accuracy: 0.2686 - val_loss: 4.5550 - val_accuracy: 0.2210\n","Epoch 18/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9021 - accuracy: 0.2638\n","Epoch 18: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9021 - accuracy: 0.2638 - val_loss: 4.9491 - val_accuracy: 0.2606\n","Epoch 19/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9122 - accuracy: 0.2615\n","Epoch 19: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.9123 - accuracy: 0.2615 - val_loss: 4.8118 - val_accuracy: 0.2288\n","Epoch 20/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9161 - accuracy: 0.2620\n","Epoch 20: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9161 - accuracy: 0.2620 - val_loss: 4.0830 - val_accuracy: 0.1840\n","Epoch 21/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.9351 - accuracy: 0.2608\n","Epoch 21: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9352 - accuracy: 0.2608 - val_loss: 7.5018 - val_accuracy: 0.1974\n","Epoch 22/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 2.0255 - accuracy: 0.2526\n","Epoch 22: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 2.0254 - accuracy: 0.2528 - val_loss: 4.6370 - val_accuracy: 0.2152\n","Epoch 23/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9290 - accuracy: 0.2734\n","Epoch 23: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9288 - accuracy: 0.2734 - val_loss: 5.1134 - val_accuracy: 0.2116\n","Epoch 24/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.9213 - accuracy: 0.2809\n","Epoch 24: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9214 - accuracy: 0.2808 - val_loss: 6.5636 - val_accuracy: 0.2322\n","Epoch 25/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 2.0823 - accuracy: 0.2448\n","Epoch 25: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 2.0825 - accuracy: 0.2446 - val_loss: 4.8087 - val_accuracy: 0.1476\n","Epoch 26/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 2.0204 - accuracy: 0.2371\n","Epoch 26: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 2.0205 - accuracy: 0.2372 - val_loss: 4.8729 - val_accuracy: 0.2484\n","Epoch 27/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.9645 - accuracy: 0.2595\n","Epoch 27: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.9644 - accuracy: 0.2595 - val_loss: 5.2267 - val_accuracy: 0.2110\n","Epoch 28/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.9818 - accuracy: 0.2563\n","Epoch 28: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.9817 - accuracy: 0.2564 - val_loss: 5.1039 - val_accuracy: 0.2060\n","Epoch 29/100\n","1407/1407 [==============================] - ETA: 0s - loss: 2.0443 - accuracy: 0.2578\n","Epoch 29: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 2.0443 - accuracy: 0.2578 - val_loss: 4.7679 - val_accuracy: 0.2418\n","Epoch 30/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9742 - accuracy: 0.2543\n","Epoch 30: saving model to chapter_11/cifar10_mc_alphadrop.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.9742 - accuracy: 0.2543 - val_loss: 5.3790 - val_accuracy: 0.1796\n"]}]},{"cell_type":"code","source":["model_alpha_dropout.evaluate(x_test_scaled, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"niFlCoY419Xj","executionInfo":{"status":"ok","timestamp":1715778315258,"user_tz":-60,"elapsed":1405,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"041e6161-ff44-4c62-d616-5fae0712b6f8"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 3.7065 - accuracy: 0.2583\n"]},{"output_type":"execute_result","data":{"text/plain":["[3.706463575363159, 0.2583000063896179]"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["# MC Dropout during inference\n","def mc_dropout_predict(model, x, n_iter=50):\n","    predictions = np.zeros((n_iter, x.shape[0], 10))\n","    for i in range(n_iter):\n","        predictions[i] = model(x, training=True)  # Keep dropout active\n","    return predictions.mean(axis=0), predictions.std(axis=0)"],"metadata":{"id":"Lsqc7Smhzsru","executionInfo":{"status":"ok","timestamp":1715778346332,"user_tz":-60,"elapsed":468,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# Get predictions with MC Dropout\n","mean_predictions, std_predictions = mc_dropout_predict(model_alpha_dropout, x_test_scaled)\n","\n","# Evaluate model using the mean predictions\n","mc_accuracy = np.mean(np.argmax(mean_predictions, axis=1) == np.argmax(y_test, axis=1))\n","print(f'MC Dropout accuracy: {mc_accuracy}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzBMO2gh2KsD","executionInfo":{"status":"ok","timestamp":1715778369380,"user_tz":-60,"elapsed":19825,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"bc7ab8b3-4fb6-4198-c210-68fa3a956f74"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["MC Dropout accuracy: 0.2629\n"]}]},{"cell_type":"code","source":["checkpoint_path = os.path.join(chapter_dir, \"cifar10_mc_alphadrop_1cycle.weights.h5\")\n","tensorboard_log_dir = os.path.join(chapter_dir, \"logs_mc_alphadrop_1cycle\")\n","\n","# Create callbacks\n","checkpoint_cb = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n","tensorboard_cb = TensorBoard(log_dir=tensorboard_log_dir, histogram_freq=1)\n","early_stopping_cb = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"],"metadata":{"id":"LyMM0SoP2Z2W","executionInfo":{"status":"ok","timestamp":1715778461362,"user_tz":-60,"elapsed":1,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# Define the 1cycle learning rate policy\n","initial_learning_rate = 1e-4\n","max_learning_rate = 1e-2\n","step_size = len(x_train) // 32\n","\n","def scale_fn(x):\n","    return 1 / (2. ** (x - 1))\n","\n","clr = tfa.optimizers.CyclicalLearningRate(\n","    initial_learning_rate=initial_learning_rate,\n","    maximal_learning_rate=max_learning_rate,\n","    step_size=step_size,\n","    scale_fn=scale_fn,\n","    scale_mode=\"cycle\",\n","    name=\"CyclicalLearningRate\"\n",")"],"metadata":{"id":"2SfB0WwC40hH","executionInfo":{"status":"ok","timestamp":1715778465952,"user_tz":-60,"elapsed":460,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# Compile the model with Nadam optimizer using the 1cycle learning rate policy\n","optimizer = Nadam(learning_rate=clr)\n","model_alpha_dropout.compile(optimizer=optimizer,\n","                            loss='categorical_crossentropy',\n","                            metrics=['accuracy'])"],"metadata":{"id":"Mo0EQPGc5Ynv","executionInfo":{"status":"ok","timestamp":1715778474131,"user_tz":-60,"elapsed":1394,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# Train the model with callbacks\n","history_alpha_dropout_clr = model_alpha_dropout.fit(x_train_scaled, y_train,\n","                                                    epochs=100,\n","                                                    batch_size=32,\n","                                                    validation_split=.1,\n","                                                    callbacks=[checkpoint_cb, tensorboard_cb, early_stopping_cb])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a48UksjZ52l4","executionInfo":{"status":"ok","timestamp":1715779194011,"user_tz":-60,"elapsed":714800,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"f2a43b03-26b3-439b-e66e-49ba09c09354"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 2.3165 - accuracy: 0.1818\n","Epoch 1: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 30s 14ms/step - loss: 2.3165 - accuracy: 0.1817 - val_loss: 2.6613 - val_accuracy: 0.1024\n","Epoch 2/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 2.3542 - accuracy: 0.1008\n","Epoch 2: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 2.3542 - accuracy: 0.1008 - val_loss: 2.3397 - val_accuracy: 0.1024\n","Epoch 3/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 2.3216 - accuracy: 0.1013\n","Epoch 3: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 2.3216 - accuracy: 0.1013 - val_loss: 2.3711 - val_accuracy: 0.0950\n","Epoch 4/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 2.3476 - accuracy: 0.0991\n","Epoch 4: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 2.3476 - accuracy: 0.0991 - val_loss: 2.3723 - val_accuracy: 0.0950\n","Epoch 5/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 2.2527 - accuracy: 0.1308\n","Epoch 5: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 2.2528 - accuracy: 0.1308 - val_loss: 2.3872 - val_accuracy: 0.1310\n","Epoch 6/100\n","1407/1407 [==============================] - ETA: 0s - loss: 2.2061 - accuracy: 0.1598\n","Epoch 6: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 2.2061 - accuracy: 0.1598 - val_loss: 2.1861 - val_accuracy: 0.1566\n","Epoch 7/100\n","1407/1407 [==============================] - ETA: 0s - loss: 2.1130 - accuracy: 0.1701\n","Epoch 7: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 2.1130 - accuracy: 0.1701 - val_loss: 2.1966 - val_accuracy: 0.1894\n","Epoch 8/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 2.0805 - accuracy: 0.1785\n","Epoch 8: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 2.0806 - accuracy: 0.1785 - val_loss: 2.2778 - val_accuracy: 0.1540\n","Epoch 9/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 2.0558 - accuracy: 0.1881\n","Epoch 9: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 2.0559 - accuracy: 0.1880 - val_loss: 2.7790 - val_accuracy: 0.1836\n","Epoch 10/100\n","1407/1407 [==============================] - ETA: 0s - loss: 2.0209 - accuracy: 0.1988\n","Epoch 10: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 2.0209 - accuracy: 0.1988 - val_loss: 3.0545 - val_accuracy: 0.1588\n","Epoch 11/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9958 - accuracy: 0.2116\n","Epoch 11: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.9957 - accuracy: 0.2116 - val_loss: 2.5466 - val_accuracy: 0.1934\n","Epoch 12/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9779 - accuracy: 0.2182\n","Epoch 12: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9780 - accuracy: 0.2181 - val_loss: 2.7382 - val_accuracy: 0.1652\n","Epoch 13/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9711 - accuracy: 0.2221\n","Epoch 13: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9711 - accuracy: 0.2221 - val_loss: 2.8027 - val_accuracy: 0.1792\n","Epoch 14/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.9555 - accuracy: 0.2284\n","Epoch 14: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9555 - accuracy: 0.2284 - val_loss: 2.8604 - val_accuracy: 0.1794\n","Epoch 15/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.9490 - accuracy: 0.2334\n","Epoch 15: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9491 - accuracy: 0.2334 - val_loss: 2.7949 - val_accuracy: 0.1796\n","Epoch 16/100\n","1403/1407 [============================>.] - ETA: 0s - loss: 1.9392 - accuracy: 0.2368\n","Epoch 16: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9393 - accuracy: 0.2367 - val_loss: 3.1055 - val_accuracy: 0.2014\n","Epoch 17/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9363 - accuracy: 0.2417\n","Epoch 17: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9363 - accuracy: 0.2417 - val_loss: 2.9017 - val_accuracy: 0.2046\n","Epoch 18/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9227 - accuracy: 0.2461\n","Epoch 18: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9227 - accuracy: 0.2461 - val_loss: 2.8898 - val_accuracy: 0.1932\n","Epoch 19/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9190 - accuracy: 0.2500\n","Epoch 19: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9190 - accuracy: 0.2500 - val_loss: 2.7717 - val_accuracy: 0.1954\n","Epoch 20/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.9122 - accuracy: 0.2500\n","Epoch 20: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9122 - accuracy: 0.2500 - val_loss: 2.6159 - val_accuracy: 0.2156\n","Epoch 21/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9068 - accuracy: 0.2566\n","Epoch 21: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9068 - accuracy: 0.2565 - val_loss: 2.6255 - val_accuracy: 0.2070\n","Epoch 22/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9096 - accuracy: 0.2548\n","Epoch 22: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9096 - accuracy: 0.2548 - val_loss: 2.5592 - val_accuracy: 0.2210\n","Epoch 23/100\n","1406/1407 [============================>.] - ETA: 0s - loss: 1.9001 - accuracy: 0.2582\n","Epoch 23: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9001 - accuracy: 0.2582 - val_loss: 2.4442 - val_accuracy: 0.2128\n","Epoch 24/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.9028 - accuracy: 0.2608\n","Epoch 24: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.9026 - accuracy: 0.2607 - val_loss: 2.3976 - val_accuracy: 0.2340\n","Epoch 25/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.9040 - accuracy: 0.2599\n","Epoch 25: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.9039 - accuracy: 0.2599 - val_loss: 2.4618 - val_accuracy: 0.2170\n","Epoch 26/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.9036 - accuracy: 0.2611\n","Epoch 26: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.9036 - accuracy: 0.2611 - val_loss: 2.4452 - val_accuracy: 0.2136\n","Epoch 27/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.8942 - accuracy: 0.2615\n","Epoch 27: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.8942 - accuracy: 0.2616 - val_loss: 2.4670 - val_accuracy: 0.1990\n","Epoch 28/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.8892 - accuracy: 0.2646\n","Epoch 28: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.8892 - accuracy: 0.2647 - val_loss: 2.3974 - val_accuracy: 0.2128\n","Epoch 29/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.8903 - accuracy: 0.2661\n","Epoch 29: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.8904 - accuracy: 0.2660 - val_loss: 2.4117 - val_accuracy: 0.2148\n","Epoch 30/100\n","1407/1407 [==============================] - ETA: 0s - loss: 1.8867 - accuracy: 0.2641\n","Epoch 30: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.8867 - accuracy: 0.2641 - val_loss: 2.4677 - val_accuracy: 0.2162\n","Epoch 31/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.8795 - accuracy: 0.2680\n","Epoch 31: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.8794 - accuracy: 0.2679 - val_loss: 2.4692 - val_accuracy: 0.2304\n","Epoch 32/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.8900 - accuracy: 0.2701\n","Epoch 32: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.8899 - accuracy: 0.2700 - val_loss: 2.4968 - val_accuracy: 0.2108\n","Epoch 33/100\n","1404/1407 [============================>.] - ETA: 0s - loss: 1.8801 - accuracy: 0.2665\n","Epoch 33: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.8801 - accuracy: 0.2665 - val_loss: 2.4008 - val_accuracy: 0.2302\n","Epoch 34/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.8768 - accuracy: 0.2707\n","Epoch 34: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.8769 - accuracy: 0.2706 - val_loss: 2.3740 - val_accuracy: 0.2232\n","Epoch 35/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.8739 - accuracy: 0.2727\n","Epoch 35: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.8738 - accuracy: 0.2727 - val_loss: 2.3381 - val_accuracy: 0.2242\n","Epoch 36/100\n","1405/1407 [============================>.] - ETA: 0s - loss: 1.8945 - accuracy: 0.2695\n","Epoch 36: saving model to chapter_11/cifar10_mc_alphadrop_1cycle.weights.h5\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.8944 - accuracy: 0.2695 - val_loss: 2.3953 - val_accuracy: 0.2246\n"]}]},{"cell_type":"code","source":["model_alpha_dropout.evaluate(x_test_scaled, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKM6c0xI57h_","executionInfo":{"status":"ok","timestamp":1715779471358,"user_tz":-60,"elapsed":61722,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"9bbff44b-a12d-40cc-c36b-2ebc69357119"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 2.1947 - accuracy: 0.1579\n"]},{"output_type":"execute_result","data":{"text/plain":["[2.1946864128112793, 0.15790000557899475]"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["# Get predictions with MC Dropout\n","mean_predictions, std_predictions = mc_dropout_predict(model_alpha_dropout, x_test_scaled)\n","\n","# Evaluate model using the mean predictions\n","mc_accuracy = np.mean(np.argmax(mean_predictions, axis=1) == np.argmax(y_test, axis=1))\n","print(f'MC Dropout accuracy: {mc_accuracy}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhzU2es6BQzB","executionInfo":{"status":"ok","timestamp":1715779520095,"user_tz":-60,"elapsed":23598,"user":{"displayName":"Ivanny Jetro","userId":"13702053412327783380"}},"outputId":"7188314b-06ed-4765-9e83-05d9cfa0f333"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["MC Dropout accuracy: 0.1588\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5nVfhwqSbWaw"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}